{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import hdf5plugin\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from unyt import yr, Myr, kpc, arcsec, nJy, Mpc, Msun, erg, s, Hz, kelvin\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "from scipy import signal\n",
    "\n",
    "from synthesizer.emission_models.attenuation import PowerLaw\n",
    "from synthesizer.filters import UVJ\n",
    "from synthesizer.grid import Grid\n",
    "from synthesizer.load_data.load_camels import load_CAMELS_IllustrisTNG\n",
    "from synthesizer.sed import Sed\n",
    "from synthesizer.parametric import SFH, ZDist\n",
    "from synthesizer.particle.stars import sample_sfhz\n",
    "from synthesizer.parametric import Stars as ParametricStars\n",
    "from synthesizer.particle.particles import CoordinateGenerator\n",
    "from synthesizer.filters import Filter, FilterCollection\n",
    "from synthesizer.sed import combine_list_of_seds\n",
    "from synthesizer.kernel_functions import Kernel\n",
    "from synthesizer.conversions import lnu_to_absolute_mag\n",
    "from synthesizer.emission_models.attenuation import PowerLaw\n",
    "from synthesizer.emission_models.dust.emission import Blackbody, Greybody\n",
    "from synthesizer.emission_models import (\n",
    "    EmissionModel,\n",
    "    AttenuatedEmission,\n",
    "    BimodalPacmanEmission,\n",
    "    DustEmission,\n",
    "    EmissionModel,\n",
    "    UnifiedAGN,\n",
    "    CharlotFall2000,\n",
    "    IncidentEmission,\n",
    "    NebularEmission,\n",
    "    ReprocessedEmission,\n",
    "    StellarEmissionModel,\n",
    ")\n",
    "from synthesizer.conversions import lnu_to_absolute_mag, fnu_to_apparent_mag, fnu_to_lnu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "\n",
    "# Absolute magnitude is defined to be the apparent magnitude an object would have if it were located at a distance of 10 parsecs.\n",
    "# In astronomy, absolute magnitude (M) is a measure of the luminosity of a celestial object on an inverse logarithmic astronomical magnitude scale.\n",
    "# only need this apparent mag function if using Mats code for calculating UVLF.\n",
    "def apparent_magnitude_from_absolute(redshift, absolute_magnitude):\n",
    "    # Get the luminosity distance for the given redshift\n",
    "    # Distnaces are in parsecs\n",
    "    d_L_pc = Planck18.luminosity_distance(redshift).to('pc').value\n",
    "    \n",
    "    # Calculate the apparent magnitude using the distance modulus formula\n",
    "    apparent_mag = absolute_magnitude - 5 + (5 * np.log10(d_L_pc))\n",
    "    \n",
    "    return apparent_mag\n",
    "\n",
    "# Alternative method for LF:\n",
    "# try this method again, but using AB mag instead of mass, and suply your own bins (up to -17, say)\n",
    "def calc_df(ab_mag, volume, massBinLimits):\n",
    "\n",
    "# OG:        hist, dummy = np.histogram(np.log10(mstar), bins = massBinLimits)\n",
    "        hist, dummy = np.histogram(ab_mag, bins = massBinLimits)\n",
    "        hist = np.float64(hist)\n",
    "        phi = (hist / volume) / (massBinLimits[1] - massBinLimits[0])\n",
    "\n",
    "        phi_sigma = (np.sqrt(hist) / volume) /\\\n",
    "                    (massBinLimits[1] - massBinLimits[0]) # Poisson errors\n",
    "\n",
    "        return phi, phi_sigma, hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grid for all galaxies\n",
    "# gives grid of metalicity and age which is used to map on our camels galaxies\n",
    "grid_name = \"bc03_chabrier03-0.1,100.hdf5\"\n",
    "#grid_name = \"bc03-2016-Miles_chabrier-0.1,100.hdf5\" # try old grid, LF looks weird?!\n",
    "grid_dir = \"/home/jovyan/\"\n",
    "grid = Grid(grid_name, grid_dir=grid_dir, read_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gals\n",
    "output_dir = '/home/jovyan/camels/CV_set/CV_outputs/LFs/'\n",
    "directories = [f'CV_{i}' for i in range(0, 27)]\n",
    "skipped_directories = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get filters:\n",
    "# Need to use the grid lam, dont need to define wavelengths here: see codes here: http://svo2.cab.inta-csic.es/theory/fps/index.php?id=Swift/UVOT.UVM2&&mode=browse&gname=Swift&gname2=UVOT#filter\n",
    "# need to use transmission NOT area\n",
    "# Get for XMM\n",
    "fil_uvm2_XMM = Filter(\"XMM/OM.UVM2_filter\", new_lam=grid.lam)\n",
    "\n",
    "# now get for UVOT\n",
    "fil_uvm2_UVOT = Filter(\"Swift/UVOT.UVM2_fil\", new_lam=grid.lam) # changed from new_lam=lams_uvot to grid.lam and get 0 transmission, but warning sign is back\n",
    "\n",
    "# what is a top hat filter?\n",
    "filt1 = Filter(\"top_hat/filter.1\", lam_min=1400, lam_max=1600, new_lam=grid.lam)\n",
    "\n",
    "# 0 = TopHat, 1 = XMM, 2= Swift\n",
    "filt_lst = [filt1, fil_uvm2_XMM, fil_uvm2_UVOT]\n",
    "\n",
    "# get filters in combined array to apply to all galaxies\n",
    "combined_filters = FilterCollection(\n",
    "    filters=filt_lst, new_lam=grid.lam\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set incident emission model\n",
    "incident = IncidentEmission(grid)\n",
    "# set little h value\n",
    "little_h =  0.6711\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/unyt/array.py:1949: RuntimeWarning: invalid value encountered in divide\n",
      "  out_arr = func(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_0.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_1.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_2.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_3.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_4.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_5.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_6.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_7.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_8.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_9.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_10.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_11.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_12.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_13.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_14.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_15.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_16.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_17.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_18.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_19.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_20.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_21.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_22.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_23.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_24.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_25.txt\n",
      "Written out: /home/jovyan/camels/CV_set/CV_outputs/LFs/CV_26.txt\n"
     ]
    }
   ],
   "source": [
    "for CV_X in directories:\n",
    "    try:\n",
    "        # create an empty dictionary to store your data - reset in loop\n",
    "        data_dict = {}\n",
    "        \n",
    "        # Get grid for all galaxies\n",
    "        dir_ = '/home/jovyan/Data/Sims/IllustrisTNG/CV/' + CV_X\n",
    "        gals_074 = load_CAMELS_IllustrisTNG(\n",
    "            dir_,\n",
    "            snap_name='snapshot_074.hdf5', \n",
    "            group_name='groups_074.hdf5',\n",
    "        )\n",
    "        \n",
    "        cat_074 = dir_+'/groups_074.hdf5'\n",
    "        \n",
    "        # open file\n",
    "        f = h5py.File(cat_074, 'r')\n",
    "        \n",
    "        # read different attributes of the header\n",
    "        boxSize_074 = f['Header'].attrs[u'BoxSize']/1e3 #Mpc/h\n",
    "        redshift_074 = f['Header'].attrs[u'Redshift']\n",
    "\n",
    "        # Filter galaxies to only include those with 100 or more star particles\n",
    "        ## NEED TO ADD FILTER TO GET RID OF ANY GALAXIES WITH LESS THAN 100 star Particles!! This is the resolution limit!!\n",
    "        # Chris: when you load your galaxies in could you do a filter for those with at least 100 star particles? that's the resolution limit\n",
    "        \n",
    "        # Filter galaxies to only include those with 100 or more star particles\n",
    "        gals_074 = [gal for gal in gals_074 if gal.stars.nstars >= 100]\n",
    "        gals_074 = [gal for gal in gals_074 if gal.gas.nparticles >= 100]\n",
    "        #gals_074 = [gal for gal in gals_074 if len(gal.stars.ages) >= 100]  # this shouldnt be here?! donesnt make sense\n",
    "\n",
    "        spec_list = []\n",
    "        # Lets work with z=0 so gals_025\n",
    "        for i in gals_074:\n",
    "            gal = i\n",
    "            # get_spectra_incident An Sed object containing the stellar spectra\n",
    "            spec = gal.stars.get_spectra(incident)\n",
    "            spec.get_fnu0()\n",
    "            spec_list.append(spec)\n",
    "\n",
    "        # combine our seds\n",
    "        seds = combine_list_of_seds(spec_list)\n",
    "        seds.lnu  # get luminosity\n",
    "\n",
    "        # get rest frame photometry for our filters\n",
    "        phot = seds.get_photo_lnu(combined_filters, verbose=True) \n",
    "        \n",
    "        # now using the filters which got the rest frame lum, get the abs magnitude in those filters\n",
    "        #abs_mags = [lnu_to_absolute_mag(phot[f]) for f in combined_filters.filters]\n",
    "        # just want top hat filter for now\n",
    "        abs_mag_th = [lnu_to_absolute_mag(phot[f]) for f in combined_filters.filters]\n",
    "\n",
    "        # next steps, get luminosity function for these magnitudes\n",
    "        # co-moving volume: BoxSize_025 and redshift:\n",
    "        little_h =  0.6711\n",
    "        Vphys = (boxSize_074/little_h )**3\n",
    "        Vcom = Vphys * ((1+redshift_074)**3)\n",
    "        \n",
    "         # Define the bin edges for AB magnitudes\n",
    "        # Here, let's define bins from -25 to -17 in steps of 0.5 magnitude\n",
    "        massBinLimits = np.arange(-22, -16, 0.5)\n",
    "\n",
    "        # calc LF\n",
    "        phi, phi_sigma, hist = calc_df(abs_mag_th, Vcom, massBinLimits)\n",
    "        \n",
    "        # Define output file path\n",
    "        output_file = f\"{output_dir}{CV_X}.txt\"\n",
    "\n",
    "        # Write the data to the text file\n",
    "        with open(output_file, 'w') as txtfile:\n",
    "            # Write phi values\n",
    "            txtfile.write(\"phi\\n\")\n",
    "            for value in phi:\n",
    "                txtfile.write(f\"{value}\\n\")\n",
    "\n",
    "            # Write phi_sigma values\n",
    "            txtfile.write(\"phi_sigma\\n\")\n",
    "            for value in phi_sigma:\n",
    "                txtfile.write(f\"{value}\\n\")\n",
    "\n",
    "            # Write hist values\n",
    "            txtfile.write(\"hist\\n\")\n",
    "            for value in hist:\n",
    "                txtfile.write(f\"{value}\\n\")\n",
    "\n",
    "            # Write massBinLimits values\n",
    "            txtfile.write(\"massBinLimits\\n\")\n",
    "            for value in massBinLimits:\n",
    "                txtfile.write(f\"{value}\\n\")\n",
    "\n",
    "        print(f'Written out: {output_file}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {CV_X}: {e}\")\n",
    "        skipped_directories.append(CV_X)\n",
    "\n",
    "# Print skipped directories at the end\n",
    "if skipped_directories:\n",
    "    print(\"Skipped directories:\", skipped_directories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot as test. will only do last one in array\n",
    "label_025 = 'z = ', redshift_074\n",
    "label_th = 'Tophat'\n",
    "\n",
    "\n",
    "\n",
    "# Plot the luminosity function\n",
    "plt.errorbar(massBinLimits[:-1], phi_th, yerr=phi_sigma_th, fmt='o', color='blue', label=label_th)\n",
    "\n",
    "plt.xlabel('Absolute Magnitude (AB)')\n",
    "plt.ylabel('Number Density (Mpc^-3 mag^-1)')\n",
    "plt.yscale('log')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "\n",
    "plt.title('Luminosity Function Top Hat filter')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
