{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model in  /disk/xray15/aem2/data/28pams/IllustrisTNG/SB/models/lf_only/\n",
      "Saving plots in  /disk/xray15/aem2/plots/28pams/IllustrisTNG/SB/test/sbi_plots/lfs_only/\n"
     ]
    }
   ],
   "source": [
    "# Key Concepts\n",
    "'''\n",
    "1. Forward problem: θ → x (simulation)\n",
    "2. Inverse problem: x → θ (what we're solving)\n",
    "3. Posterior: P(θ|x) probability distribution over parameters\n",
    "4. Prior: Initial assumptions about parameter ranges\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# seaparate into train and test set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import torch\n",
    "#from torch.distributions import Uniform, ExpTransform, TransformedDistribution #, AffineTransform\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import joblib\n",
    "import os \n",
    "import ili\n",
    "from ili.dataloaders import NumpyLoader\n",
    "from ili.inference import InferenceRunner\n",
    "from ili.validation.metrics import PosteriorCoverage#, PlotSinglePosterior\n",
    "\n",
    "from sbi.utils.user_input_checks import process_prior\n",
    "\n",
    "sys.path.append(\"/disk/xray15/aem2/camels/proj2\")\n",
    "from setup_params_1P import plot_uvlf, plot_colour\n",
    "from setup_params_SB import *\n",
    "from priors_SB import initialise_priors_SB28\n",
    "\n",
    "from variables_config_28 import uvlf_limits, n_bins_lf, colour_limits, n_bins_colour\n",
    "# parameters\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = \"IllustrisTNG\"\n",
    "spec_type = \"attenuated\"\n",
    "sps = \"BC03\"\n",
    "snap = [\"044\"]\n",
    "bands = \"all\" # or just GALEX?\n",
    "\n",
    "# lets try UVLF and colours this time.\n",
    "colours = False  \n",
    "luminosity_functions = True\n",
    "name = f\"{model}_{bands}_{sps}_{spec_type}_{n_bins_lf}_{n_bins_colour}\"\n",
    "\n",
    "# initialize CAMELS and load parameter info using camels.py\n",
    "cam = camels(model=model, sim_set='SB28')\n",
    "\n",
    "if colours and not luminosity_functions:\n",
    "    model_out_dir = \"/disk/xray15/aem2/data/28pams/IllustrisTNG/SB/models/colours_only/\"\n",
    "    plots_out_dir = \"/disk/xray15/aem2/plots/28pams/IllustrisTNG/SB/test/sbi_plots/colours_only/\"\n",
    "    \n",
    "elif luminosity_functions and not colours:\n",
    "    model_out_dir = \"/disk/xray15/aem2/data/28pams/IllustrisTNG/SB/models/lf_only/\"\n",
    "    plots_out_dir = \"/disk/xray15/aem2/plots/28pams/IllustrisTNG/SB/test/sbi_plots/lfs_only/\"\n",
    "\n",
    "elif colours and luminosity_functions:\n",
    "    model_out_dir = \"/disk/xray15/aem2/data/28pams/IllustrisTNG/SB/models/colours_lfs/\"\n",
    "    plots_out_dir = \"/disk/xray15/aem2/plots/28pams/IllustrisTNG/SB/test/sbi_plots/colours_lfs/\"\n",
    "\n",
    "# You might want to add an else for safety:\n",
    "else:\n",
    "    raise ValueError(\"At least one of colours or luminosity_functions must be True\")\n",
    "\n",
    "print(\"Saving model in \", model_out_dir)\n",
    "print(\"Saving plots in \", plots_out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          #Name    Omega0    sigma8  WindEnergyIn1e51erg  RadioFeedbackFactor  \\\n",
      "0        SB28_0  0.352541  0.694742              3.85743             1.519210   \n",
      "1        SB28_1  0.172430  0.830154              1.03554             0.797734   \n",
      "2        SB28_2  0.234683  0.705844              9.61416             3.380650   \n",
      "3        SB28_3  0.440288  0.969259              2.14363             0.488165   \n",
      "4        SB28_4  0.457152  0.786733              1.38466             0.325727   \n",
      "...         ...       ...       ...                  ...                  ...   \n",
      "2043  SB28_2043  0.457334  0.970226              8.89733             0.607197   \n",
      "2044  SB28_2044  0.440496  0.786137              5.34131             0.880840   \n",
      "2045  SB28_2045  0.234475  0.938760              1.49723             1.873430   \n",
      "2046  SB28_2046  0.172613  0.612888             13.31250             0.363806   \n",
      "2047  SB28_2047  0.352358  0.862216              3.09935             3.331570   \n",
      "\n",
      "      VariableWindVelFactor  RadioFeedbackReiorientationFactor  OmegaBaryon  \\\n",
      "0                   9.09267                            14.2845     0.049404   \n",
      "1                   6.95693                            38.2374     0.031199   \n",
      "2                   3.77681                            24.6592     0.042995   \n",
      "3                  11.49660                            10.9550     0.062295   \n",
      "4                  13.19410                            17.1439     0.044425   \n",
      "...                     ...                                ...          ...   \n",
      "2043                3.75653                            39.5139     0.046041   \n",
      "2044                5.04789                            21.6844     0.063161   \n",
      "2045               13.26680                            13.5869     0.042461   \n",
      "2046                8.64069                            17.7159     0.029257   \n",
      "2047                5.64656                            33.6239     0.051052   \n",
      "\n",
      "      HubbleParam       n_s  ...  WindEnergyReductionExponent  WindDumpFactor  \\\n",
      "0        0.498145  0.795765  ...                      1.61148        0.435971   \n",
      "1        0.683693  1.142160  ...                      2.08951        0.612056   \n",
      "2        0.849506  0.923545  ...                      1.33988        0.878906   \n",
      "3        0.638970  0.964648  ...                      2.86478        0.253435   \n",
      "4        0.773770  0.900256  ...                      2.59030        0.944457   \n",
      "...           ...       ...  ...                          ...             ...   \n",
      "2043     0.513293  0.828903  ...                      1.88784        0.725070   \n",
      "2044     0.748997  1.143290  ...                      1.66098        0.472330   \n",
      "2045     0.534548  0.796116  ...                      2.13803        0.698393   \n",
      "2046     0.600362  0.965127  ...                      1.38572        0.818457   \n",
      "2047     0.789823  0.924799  ...                      2.90964        0.242951   \n",
      "\n",
      "      SeedBlackHoleMass  BlackHoleAccretionFactor  BlackHoleEddingtonFactor  \\\n",
      "0              0.000069                  1.111740                  2.613460   \n",
      "1              0.000094                  0.889955                  0.302262   \n",
      "2              0.000153                  0.364219                  8.235920   \n",
      "3              0.000041                  2.775960                  0.950425   \n",
      "4              0.000049                  0.286789                  1.121900   \n",
      "...                 ...                       ...                       ...   \n",
      "2043           0.000054                  0.327481                  4.790910   \n",
      "2044           0.000038                  2.229260                  0.222157   \n",
      "2045           0.000174                  0.453541                  1.920250   \n",
      "2046           0.000090                  0.718570                  0.698528   \n",
      "2047           0.000070                  1.376900                  6.051620   \n",
      "\n",
      "      BlackHoleFeedbackFactor  BlackHoleRadiativeEfficiency  QuasarThreshold  \\\n",
      "0                    0.039463                      0.225386         0.000269   \n",
      "1                    0.151352                      0.086231         0.022802   \n",
      "2                    0.099772                      0.648096         0.001458   \n",
      "3                    0.349945                      0.126670         0.004242   \n",
      "4                    0.032352                      0.460414         0.007438   \n",
      "...                       ...                           ...              ...   \n",
      "2043                 0.033553                      0.481742         0.001252   \n",
      "2044                 0.397001                      0.109068         0.000416   \n",
      "2045                 0.087029                      0.682619         0.006263   \n",
      "2046                 0.158683                      0.083655         0.000071   \n",
      "2047                 0.038037                      0.256220         0.036493   \n",
      "\n",
      "      QuasarThresholdPower   seed  \n",
      "0                 0.514648  20000  \n",
      "1                 2.620780  20001  \n",
      "2                 3.389560  20002  \n",
      "3                 1.494400  20003  \n",
      "4                 2.299550  20004  \n",
      "...                    ...    ...  \n",
      "2043              2.191720  22043  \n",
      "2044              1.012360  22044  \n",
      "2045              3.117210  22045  \n",
      "2046              2.887940  22046  \n",
      "2047              0.994068  22047  \n",
      "\n",
      "[2048 rows x 30 columns]\n",
      "                            ParamName  AbsMaxDiff  LogFlag  FiducialVal  \\\n",
      "0                              Omega0        0.20        0      0.30000   \n",
      "1                              sigma8        0.20        0      0.80000   \n",
      "2                 WindEnergyIn1e51erg        4.00        1      3.60000   \n",
      "3                 RadioFeedbackFactor        4.00        1      1.00000   \n",
      "4               VariableWindVelFactor        2.00        1      7.40000   \n",
      "5   RadioFeedbackReiorientationFactor        2.00        1     20.00000   \n",
      "6                         OmegaBaryon        0.02        0      0.04900   \n",
      "7                         HubbleParam        0.20        0      0.67110   \n",
      "8                                 n_s        0.20        0      0.96240   \n",
      "9                     MaxSfrTimescale        2.00        1      2.27000   \n",
      "10                 FactorForSofterEQS        3.00        1      0.30000   \n",
      "11                           IMFslope        0.50        0     -2.30000   \n",
      "12                  SNII_MinMass_Msun        4.00        0      8.00000   \n",
      "13                ThermalWindFraction        4.00        1      0.10000   \n",
      "14           VariableWindSpecMomentum     2000.00        0      0.00000   \n",
      "15              WindFreeTravelDensFac       10.00        1      0.05000   \n",
      "16                         MinWindVel      200.00        0    350.00000   \n",
      "17          WindEnergyReductionFactor        4.00        1      0.25000   \n",
      "18     WindEnergyReductionMetallicity        4.00        1      0.00200   \n",
      "19        WindEnergyReductionExponent        1.00        0      2.00000   \n",
      "20                     WindDumpFactor        0.40        0      0.60000   \n",
      "21                  SeedBlackHoleMass        3.16        1      0.00008   \n",
      "22           BlackHoleAccretionFactor        4.00        1      1.00000   \n",
      "23           BlackHoleEddingtonFactor       10.00        1      1.00000   \n",
      "24            BlackHoleFeedbackFactor        4.00        1      0.10000   \n",
      "25       BlackHoleRadiativeEfficiency        4.00        1      0.20000   \n",
      "26                    QuasarThreshold       31.60        1      0.00200   \n",
      "27               QuasarThresholdPower        2.00        0      2.00000   \n",
      "\n",
      "        MinVal       MaxVal                                        Description  \n",
      "0     0.100000     0.500000                                        OmegaMatter  \n",
      "1     0.600000     1.000000                                             sigma8  \n",
      "2     0.900000    14.400000                       ASN1 - galactic winds energy  \n",
      "3     0.250000     4.000000                 AAGN1 - AGN FB kinetic mode energy  \n",
      "4     3.700000    14.800000                        ASN2 - galactic winds speed  \n",
      "5    10.000000    40.000000             AAGN2 - AGN FB kinetic mode burstiness  \n",
      "6     0.029000     0.069000                                        OmegaBaryon  \n",
      "7     0.471100     0.871100                                   Hubble parameter  \n",
      "8     0.762400     1.162400                      power spectrum spectral index  \n",
      "9     1.135000     4.540000                          gas consumption timescale  \n",
      "10    0.100000     0.900000                     softening factor for SH03 eEOS  \n",
      "11   -2.800000    -1.800000                              IMF slope above 1Msun  \n",
      "12    4.000000    12.000000                  minimum stellar mass that goes SN  \n",
      "13    0.025000     0.400000  fraction of wind energy injected thermally (ve...  \n",
      "14    0.000000  4000.000000              wind momentum per unit star-formation  \n",
      "15    0.005000     0.500000                         density of wind recoupling  \n",
      "16  150.000000   550.000000                                   wind speed floor  \n",
      "17    0.062500     1.000000  magnitude of wind energy dependence on metalli...  \n",
      "18    0.000500     0.008000            metallicity at which wind energy pivots  \n",
      "19    1.000000     3.000000  sharpness of wind energy dependence on metalli...  \n",
      "20    0.200000     1.000000                   (1 minus metal loading of winds)  \n",
      "21    0.000025     0.000253                                       seed BH mass  \n",
      "22    0.250000     4.000000                              Bondi rate multiplier  \n",
      "23    0.100000    10.000000  Eddington rate multiplier for the BH accretion...  \n",
      "24    0.025000     0.400000            high-accretion mode feedback efficiency  \n",
      "25    0.050000     0.800000                            BH radiative efficiency  \n",
      "26    0.000063     0.063200  Eddington ratio for transition between BH feed...  \n",
      "27    0.000000     4.000000  power-law in Weinberger+ 2017 eq.5 - steepness...  \n"
     ]
    }
   ],
   "source": [
    "# parameter info file (df_info) is used for defining priors\n",
    "# the actual parameter values come from the camels class which reads CosmoAstroSeed_IllustrisTNG_L25n256_SB28.txt\n",
    "\n",
    "#  parameters defined here: /disk/xray15/aem2/data/28pams/IllustrisTNG/SB/CosmoAstroSeed_IllustrisTNG_L25n256_SB28.txt which is used for theta\n",
    "df_pars = pd.read_csv('/disk/xray15/aem2/data/28pams/IllustrisTNG/SB/CosmoAstroSeed_IllustrisTNG_L25n256_SB28.txt', delim_whitespace=True)\n",
    "print(df_pars)\n",
    "\n",
    "\n",
    "# prior values come from this:\n",
    "df_info = pd.read_csv(\"/disk/xray15/aem2/data/28pams/Info_IllustrisTNG_L25n256_28params.txt\")\n",
    "print(df_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.52541e-01 6.94742e-01 3.85743e+00 ... 2.25386e-01 2.69356e-04\n",
      "  5.14648e-01]\n",
      " [1.72430e-01 8.30154e-01 1.03554e+00 ... 8.62311e-02 2.28022e-02\n",
      "  2.62078e+00]\n",
      " [2.34683e-01 7.05844e-01 9.61416e+00 ... 6.48096e-01 1.45761e-03\n",
      "  3.38956e+00]\n",
      " ...\n",
      " [2.34475e-01 9.38760e-01 1.49723e+00 ... 6.82619e-01 6.26319e-03\n",
      "  3.11721e+00]\n",
      " [1.72613e-01 6.12888e-01 1.33125e+01 ... 8.36555e-02 7.09853e-05\n",
      "  2.88794e+00]\n",
      " [3.52358e-01 8.62216e-01 3.09935e+00 ... 2.56220e-01 3.64932e-02\n",
      "  9.94068e-01]]\n",
      "(2048, 28)\n"
     ]
    }
   ],
   "source": [
    "theta = df_pars.iloc[:, 1:29].to_numpy()  # excluding 'name' column and 'seed' column\n",
    "\n",
    "print(theta)\n",
    "print(theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "['#Name', 'Omega0', 'sigma8', 'WindEnergyIn1e51erg', 'RadioFeedbackFactor', 'VariableWindVelFactor', 'RadioFeedbackReiorientationFactor', 'OmegaBaryon', 'HubbleParam', 'n_s', 'MaxSfrTimescale', 'FactorForSofterEQS', 'IMFslope', 'SNII_MinMass_Msun', 'ThermalWindFraction', 'VariableWindSpecMomentum', 'WindFreeTravelDensFac', 'MinWindVel', 'WindEnergyReductionFactor', 'WindEnergyReductionMetallicity', 'WindEnergyReductionExponent', 'WindDumpFactor', 'SeedBlackHoleMass', 'BlackHoleAccretionFactor', 'BlackHoleEddingtonFactor', 'BlackHoleFeedbackFactor', 'BlackHoleRadiativeEfficiency', 'QuasarThreshold', 'QuasarThresholdPower', 'seed']\n"
     ]
    }
   ],
   "source": [
    "print(\"Column names:\")\n",
    "print(df_pars.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([676., 348., 235., 178., 143., 121., 102.,  92.,  80.,  73.]),\n",
       " array([0.0250079 , 0.06248791, 0.09996792, 0.13744793, 0.17492794,\n",
       "        0.21240795, 0.24988796, 0.28736797, 0.32484798, 0.36232799,\n",
       "        0.399808  ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the first one (omega0) to see shape of prior:\n",
    "plt.hist(theta[:, 24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 28]) (2048, 36)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    theta, x = get_theta_x_SB()\n",
    "    print(theta.shape, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colours:\n",
    "    fig = plot_colour(x)\n",
    "    plt.savefig('/disk/xray15/aem2/plots/28pams/IllustrisTNG/SB/test/colours_test/colour_check.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if luminosity_functions:\n",
    "    fig = plot_uvlf(x)\n",
    "    plt.savefig('/disk/xray15/aem2/plots/28pams/IllustrisTNG/SB/test/LFs_test/uvlf_check.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing Omega0:\n",
      "processing Omega0 is linear with min 0.1 and max 0.5:\n",
      "processing sigma8:\n",
      "processing sigma8 is linear with min 0.6 and max 1.0:\n",
      "processing WindEnergyIn1e51erg:\n",
      "processing WindEnergyIn1e51erg is logarithmic with min 0.9 and max 14.4:\n",
      "processing RadioFeedbackFactor:\n",
      "processing RadioFeedbackFactor is logarithmic with min 0.25 and max 4.0:\n",
      "processing VariableWindVelFactor:\n",
      "processing VariableWindVelFactor is logarithmic with min 3.7 and max 14.8:\n",
      "processing RadioFeedbackReiorientationFactor:\n",
      "processing RadioFeedbackReiorientationFactor is logarithmic with min 10.0 and max 40.0:\n",
      "processing OmegaBaryon:\n",
      "processing OmegaBaryon is linear with min 0.029 and max 0.069:\n",
      "processing HubbleParam:\n",
      "processing HubbleParam is linear with min 0.4711 and max 0.8711:\n",
      "processing n_s:\n",
      "processing n_s is linear with min 0.7624 and max 1.1624:\n",
      "processing MaxSfrTimescale:\n",
      "processing MaxSfrTimescale is logarithmic with min 1.135 and max 4.54:\n",
      "processing FactorForSofterEQS:\n",
      "processing FactorForSofterEQS is logarithmic with min 0.1 and max 0.9:\n",
      "processing IMFslope:\n",
      "processing IMFslope is linear with min -2.8 and max -1.8:\n",
      "processing SNII_MinMass_Msun:\n",
      "processing SNII_MinMass_Msun is linear with min 4.0 and max 12.0:\n",
      "processing ThermalWindFraction:\n",
      "processing ThermalWindFraction is logarithmic with min 0.025 and max 0.4:\n",
      "processing VariableWindSpecMomentum:\n",
      "processing VariableWindSpecMomentum is linear with min 0.0 and max 4000.0:\n",
      "processing WindFreeTravelDensFac:\n",
      "processing WindFreeTravelDensFac is logarithmic with min 0.005 and max 0.5:\n",
      "processing MinWindVel:\n",
      "processing MinWindVel is linear with min 150.0 and max 550.0:\n",
      "processing WindEnergyReductionFactor:\n",
      "processing WindEnergyReductionFactor is logarithmic with min 0.0625 and max 1.0:\n",
      "processing WindEnergyReductionMetallicity:\n",
      "processing WindEnergyReductionMetallicity is logarithmic with min 0.0005 and max 0.008:\n",
      "processing WindEnergyReductionExponent:\n",
      "processing WindEnergyReductionExponent is linear with min 1.0 and max 3.0:\n",
      "processing WindDumpFactor:\n",
      "processing WindDumpFactor is linear with min 0.2 and max 1.0:\n",
      "processing SeedBlackHoleMass:\n",
      "processing SeedBlackHoleMass is logarithmic with min 2.5316e-05 and max 0.0002528:\n",
      "processing BlackHoleAccretionFactor:\n",
      "processing BlackHoleAccretionFactor is logarithmic with min 0.25 and max 4.0:\n",
      "processing BlackHoleEddingtonFactor:\n",
      "processing BlackHoleEddingtonFactor is logarithmic with min 0.1 and max 10.0:\n",
      "processing BlackHoleFeedbackFactor:\n",
      "processing BlackHoleFeedbackFactor is logarithmic with min 0.025 and max 0.4:\n",
      "processing BlackHoleRadiativeEfficiency:\n",
      "processing BlackHoleRadiativeEfficiency is logarithmic with min 0.05 and max 0.8:\n",
      "processing QuasarThreshold:\n",
      "processing QuasarThreshold is logarithmic with min 6.33e-05 and max 0.0632:\n",
      "processing QuasarThresholdPower:\n",
      "processing QuasarThresholdPower is linear with min 0.0 and max 4.0:\n",
      "Theta shape: torch.Size([2048, 28])\n",
      "X shape: torch.Size([2048, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/sbi/utils/user_input_checks.py:76: UserWarning: Prior was provided as a sequence of 28 priors. They will be\n",
      "            interpreted as independent of each other and matched in order to the\n",
      "            components of the parameter.\n",
      "  warnings.warn(\n",
      "/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/sbi/utils/torchutils.py:27: UserWarning: GPU was selected as a device for training the neural network. Note that we expect no significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  warnings.warn(\n",
      "/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/sbi/utils/user_input_checks.py:209: UserWarning: Casting 1D Uniform prior to BoxUniform to match sbi batch requirements.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get the priors and data\n",
    "prior = initialise_priors_SB28(\n",
    "    df=df_info, \n",
    "    device=device,\n",
    "    astro=True,\n",
    "    dust=False  # no dust for testing. set to False to only get the 28 model parameters.\n",
    "    # with dust = True, prior has 32 dimensions (28 parameters + 4 dust parameters) \n",
    ")\n",
    "\n",
    "# process the data\n",
    "x_all = np.array([np.hstack(_x) for _x in x])\n",
    "x_all = torch.tensor(x_all, dtype=torch.float32, device=device)\n",
    "\n",
    "print(\"Theta shape:\", theta.shape)\n",
    "print(\"X shape:\", x_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.9718e+00, -5.9718e+00, -5.9718e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-5.9881e+00, -5.9881e+00, -5.9881e+00,  ...,  6.9378e-02,\n",
       "          3.5885e-02,  2.6316e-02],\n",
       "        [-5.9762e+00, -5.9762e+00, -5.9762e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        ...,\n",
       "        [-5.9622e+00, -5.9622e+00, -5.9622e+00,  ...,  1.6349e-02,\n",
       "          8.1744e-03,  0.0000e+00],\n",
       "        [-5.9627e+00, -5.9627e+00, -5.9627e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-5.9961e+00, -5.9961e+00, -5.9961e+00,  ...,  2.5126e-02,\n",
       "          2.0101e-02,  5.0251e-03]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Move data to GPU as early as possible\n",
    "x_all = x_all.to(device)\n",
    "x_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4159290/964306182.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta = torch.tensor(theta, dtype=torch.float32, device=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3.5254e-01, 6.9474e-01, 3.8574e+00,  ..., 2.2539e-01, 2.6936e-04,\n",
       "         5.1465e-01],\n",
       "        [1.7243e-01, 8.3015e-01, 1.0355e+00,  ..., 8.6231e-02, 2.2802e-02,\n",
       "         2.6208e+00],\n",
       "        [2.3468e-01, 7.0584e-01, 9.6142e+00,  ..., 6.4810e-01, 1.4576e-03,\n",
       "         3.3896e+00],\n",
       "        ...,\n",
       "        [2.3448e-01, 9.3876e-01, 1.4972e+00,  ..., 6.8262e-01, 6.2632e-03,\n",
       "         3.1172e+00],\n",
       "        [1.7261e-01, 6.1289e-01, 1.3312e+01,  ..., 8.3655e-02, 7.0985e-05,\n",
       "         2.8879e+00],\n",
       "        [3.5236e-01, 8.6222e-01, 3.0993e+00,  ..., 2.5622e-01, 3.6493e-02,\n",
       "         9.9407e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = torch.tensor(theta, dtype=torch.float32, device=device)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.9717813e+00, -5.9717813e+00, -5.9717813e+00, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [-5.9881158e+00, -5.9881158e+00, -5.9881158e+00, ...,\n",
       "         6.9377989e-02,  3.5885166e-02,  2.6315790e-02],\n",
       "       [-5.9762177e+00, -5.9762177e+00, -5.9762177e+00, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       ...,\n",
       "       [-5.9622416e+00, -5.9622416e+00, -5.9622416e+00, ...,\n",
       "         1.6348774e-02,  8.1743868e-03,  0.0000000e+00],\n",
       "       [-5.9626508e+00, -5.9626508e+00, -5.9626508e+00, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [-5.9960556e+00, -5.9960556e+00, -5.9960556e+00, ...,\n",
       "         2.5125628e-02,  2.0100502e-02,  5.0251256e-03]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle NaN values and normalize while on GPU\n",
    "x_all_cpu = x_all.cpu().numpy()  # Only move to CPU when necessary for sklearn\n",
    "x_all_cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape before processing: (2048, 36)\n",
      "Number of values: -225130.23\n",
      "Number of NaN values: 0\n",
      "Number of infinite values: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape before processing:\", x_all_cpu.shape)\n",
    "print(\"Number of values:\",(x_all_cpu).sum())\n",
    "print(\"Number of NaN values:\", np.isnan(x_all_cpu).sum())\n",
    "print(\"Number of infinite values:\", np.isinf(x_all_cpu).sum())\n",
    "\n",
    "# how many nan values are there? if they are all nan something has gone horribly wrong.\n",
    "# this looks better - 18th Nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# get rid of NaN/inf values, replace with small random noise\n",
    "nan_mask = np.isnan(x_all_cpu) | np.isinf(x_all_cpu)\n",
    "nan_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if nan_mask.any():\n",
    "    x_all_cpu[nan_mask] = np.random.rand(np.sum(nan_mask)) * 1e-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.9717813e+00, -5.9717813e+00, -5.9717813e+00, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [-5.9881158e+00, -5.9881158e+00, -5.9881158e+00, ...,\n",
       "         6.9377989e-02,  3.5885166e-02,  2.6315790e-02],\n",
       "       [-5.9762177e+00, -5.9762177e+00, -5.9762177e+00, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       ...,\n",
       "       [-5.9622416e+00, -5.9622416e+00, -5.9622416e+00, ...,\n",
       "         1.6348774e-02,  8.1743868e-03,  0.0000000e+00],\n",
       "       [-5.9626508e+00, -5.9626508e+00, -5.9626508e+00, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [-5.9960556e+00, -5.9960556e+00, -5.9960556e+00, ...,\n",
       "         2.5125628e-02,  2.0100502e-02,  5.0251256e-03]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape before processing: (2048, 36)\n",
      "Number of NaN values: 0\n",
      "Number of infinite values: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape before processing:\", x_all_cpu.shape)\n",
    "print(\"Number of NaN values:\", np.isnan(x_all_cpu).sum())\n",
    "print(\"Number of infinite values:\", np.isinf(x_all_cpu).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3794e-01, -2.3794e-01, -2.3794e-01,  ...,  3.9845e-12,\n",
       "          3.9845e-12,  3.9845e-12],\n",
       "        [-2.4248e-01, -2.4248e-01, -2.4248e-01,  ...,  2.8094e-03,\n",
       "          1.4531e-03,  1.0656e-03],\n",
       "        [-2.5381e-01, -2.5381e-01, -2.5381e-01,  ...,  4.2469e-12,\n",
       "          4.2469e-12,  4.2469e-12],\n",
       "        ...,\n",
       "        [-2.4442e-01, -2.4442e-01, -2.4442e-01,  ...,  6.7022e-04,\n",
       "          3.3511e-04,  4.0995e-12],\n",
       "        [-2.1867e-01, -2.1867e-01, -2.1867e-01,  ...,  3.6673e-12,\n",
       "          3.6673e-12,  3.6673e-12],\n",
       "        [-2.3707e-01, -2.3707e-01, -2.3707e-01,  ...,  9.9339e-04,\n",
       "          7.9472e-04,  1.9868e-04]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Normalize\n",
    "'''\n",
    "With normalization:\n",
    "- All values brought to similar scale\n",
    "- Neural network can learn more effectively\n",
    "- No single bin dominates the learning\n",
    "'''\n",
    "\n",
    "norm = Normalizer()\n",
    "\n",
    "# Option: Add small constant before normalizing\n",
    "epsilon = 1e-10  # Small constant\n",
    "x_all_shifted = x_all_cpu + epsilon\n",
    "x_all_normalized = norm.fit_transform(x_all_shifted)\n",
    "x_all = torch.tensor(x_all_normalized, dtype=torch.float32, device=device)\n",
    "\n",
    "'''\n",
    "x_all_normalized = norm.fit_transform(x_all_cpu)\n",
    "x_all = torch.tensor(x_all_normalized, dtype=torch.float32, device=device)\n",
    "'''\n",
    "x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization Statistics:\n",
      "Mean: -0.126946\n",
      "Std: 0.107993\n",
      "Min: -0.326723\n",
      "Max: 0.131679\n",
      "Zero elements: 0 out of 73728\n"
     ]
    }
   ],
   "source": [
    "# Add some diagnostics for the normalized data\n",
    "def analyze_normalization(x_all):\n",
    "    \"\"\"Analyze the normalized data distribution\"\"\"\n",
    "    x_numpy = x_all.cpu().numpy()\n",
    "    \n",
    "    print(\"Normalization Statistics:\")\n",
    "    print(f\"Mean: {np.mean(x_numpy):.6f}\")\n",
    "    print(f\"Std: {np.std(x_numpy):.6f}\")\n",
    "    print(f\"Min: {np.min(x_numpy):.6f}\")\n",
    "    print(f\"Max: {np.max(x_numpy):.6f}\")\n",
    "    print(f\"Zero elements: {np.sum(x_numpy == 0)} out of {x_numpy.size}\")\n",
    "    \n",
    "    # Plot distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(x_numpy.flatten(), bins=50, density=True)\n",
    "    plt.title('Distribution of Normalized Values')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(plots_out_dir, 'normalization_distribution.png'))\n",
    "    plt.close()\n",
    "\n",
    "analyze_normalization(x_all)\n",
    "\n",
    "# zero elements might refer to:\n",
    "# empty magnitude bins (no galaxies in that magnitude range)\n",
    "# below detection limit regions\n",
    "# is actually normal for UVLFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaN in normalized data: False\n",
      "Any inf in normalized data: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save normalizer\n",
    "joblib.dump(norm, f'/disk/xray15/aem2/data/28pams/IllustrisTNG/SB/models/{name}_scaler.save')\n",
    "\n",
    "# Print final check\n",
    "print(\"Any NaN in normalized data:\", torch.isnan(x_all).any().item())\n",
    "print(\"Any inf in normalized data:\", torch.isinf(x_all).any().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total simulations: 2048\n",
      "Test set size: 203\n",
      "Training set size: 1845\n",
      "Test fraction: 0.099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ..., False, False, False])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# make test mask\n",
    "test_mask = create_test_mask() # 10% testing\n",
    "test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask = ~test_mask # 90% for training\n",
    "train_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/sbi/utils/torchutils.py:27: UserWarning: GPU was selected as a device for training the neural network. Note that we expect no significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  warnings.warn(\n",
      "INFO:root:Training model 1 / 1.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 65\u001b[0m\n\u001b[1;32m     51\u001b[0m runner \u001b[38;5;241m=\u001b[39m InferenceRunner\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m     52\u001b[0m     backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msbi\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m     engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNPE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m     61\u001b[0m )\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Run training - 'learn the likelihood'\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# this is training the neural network which will act like our likelihood!\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m posterior_ensemble, summaries \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# process of training:\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m- the neural network learns P(θ|x): probability of parameters given observations\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m- uses training data to learn mapping from x → θ\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m- then we validate on held-out portion of training data\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/src/ltu-ili/ili/inference/runner_sbi.py:301\u001b[0m, in \u001b[0;36mSBIRunner.__call__\u001b[0;34m(self, loader, seed)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# train a single round of inference\u001b[39;00m\n\u001b[1;32m    300\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 301\u001b[0m posterior_ensemble, summaries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_round\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproposal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproposal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mt0\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds to train models.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# save if output path is specified\u001b[39;00m\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/src/ltu-ili/ili/inference/runner_sbi.py:233\u001b[0m, in \u001b[0;36mSBIRunner._train_round\u001b[0;34m(self, models, x, theta, proposal)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNPE\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine) \u001b[38;5;241m&\u001b[39m first_round:\n\u001b[0;32m--> 233\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m                \u001b[49m\u001b[43mforce_first_round_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     model\u001b[38;5;241m.\u001b[39mepoch, model\u001b[38;5;241m.\u001b[39m_val_log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-Inf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/sbi/inference/snpe/snpe_c.py:180\u001b[0m, in \u001b[0;36mSNPE_C.train\u001b[0;34m(self, num_atoms, training_batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, calibration_kernel, resume_training, force_first_round_loss, discard_prior_samples, use_combined_loss, retrain_from_scratch, show_train_summary, dataloader_kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_non_atomic_loss:\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;66;03m# Take care of z-scoring, pre-compute and store prior terms.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_state_for_mog_proposal()\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/sbi/inference/snpe/snpe_base.py:356\u001b[0m, in \u001b[0;36mPosteriorEstimator.train\u001b[0;34m(self, training_batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, calibration_kernel, resume_training, force_first_round_loss, discard_prior_samples, retrain_from_scratch, show_train_summary, dataloader_kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;66;03m# Get batches on current device.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m theta_batch, x_batch, masks_batch \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    351\u001b[0m     batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device),\n\u001b[1;32m    352\u001b[0m     batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device),\n\u001b[1;32m    353\u001b[0m     batch[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device),\n\u001b[1;32m    354\u001b[0m )\n\u001b[0;32m--> 356\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtheta_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmasks_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproposal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcalibration_kernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_first_round_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_first_round_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(train_losses)\n\u001b[1;32m    365\u001b[0m train_log_probs_sum \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m train_losses\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/sbi/inference/snpe/snpe_base.py:577\u001b[0m, in \u001b[0;36mPosteriorEstimator._loss\u001b[0;34m(self, theta, x, masks, proposal, calibration_kernel, force_first_round_loss)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return loss with proposal correction (`round_>0`) or without it (`round_=0`).\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \n\u001b[1;32m    566\u001b[0m \u001b[38;5;124;03mThe loss is the negative log prob. Irrespective of the round or SNPE method\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m        distribution different from the prior.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_round \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m force_first_round_loss:\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# Use posterior log prob (without proposal correction) for first round.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m     log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_neural_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    579\u001b[0m     log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_prob_proposal_posterior(theta, x, masks, proposal)\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/nflows/distributions/base.py:40\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m context\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of input items must be equal to number of context items.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         )\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/nflows/flows/base.py:39\u001b[0m, in \u001b[0;36mFlow._log_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, context):\n\u001b[1;32m     38\u001b[0m     embedded_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_net(context)\n\u001b[0;32m---> 39\u001b[0m     noise, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedded_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution\u001b[38;5;241m.\u001b[39mlog_prob(noise, context\u001b[38;5;241m=\u001b[39membedded_context)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_prob \u001b[38;5;241m+\u001b[39m logabsdet\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/nflows/transforms/base.py:56\u001b[0m, in \u001b[0;36mCompositeTransform.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     55\u001b[0m     funcs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transforms\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cascade\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuncs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/nflows/transforms/base.py:50\u001b[0m, in \u001b[0;36mCompositeTransform._cascade\u001b[0;34m(inputs, funcs, context)\u001b[0m\n\u001b[1;32m     48\u001b[0m total_logabsdet \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mnew_zeros(batch_size)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[0;32m---> 50\u001b[0m     outputs, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     total_logabsdet \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m logabsdet\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, total_logabsdet\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/nflows/transforms/coupling.py:83\u001b[0m, in \u001b[0;36mCouplingTransform.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     80\u001b[0m identity_split \u001b[38;5;241m=\u001b[39m inputs[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midentity_features, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m     81\u001b[0m transform_split \u001b[38;5;241m=\u001b[39m inputs[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_features, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[0;32m---> 83\u001b[0m transform_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43midentity_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m transform_split, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coupling_transform_forward(\n\u001b[1;32m     85\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mtransform_split, transform_params\u001b[38;5;241m=\u001b[39mtransform_params\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconditional_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/nflows/nn/nets/resnet.py:96\u001b[0m, in \u001b[0;36mResidualNet.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     94\u001b[0m     temps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_layer(inputs)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     temps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m     98\u001b[0m     temps \u001b[38;5;241m=\u001b[39m block(temps, context\u001b[38;5;241m=\u001b[39mcontext)\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/disk/xray15/aem2/envs/camels/lib/python3.8/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "# NPE: train a neural network to learn the mapping between the observed data and the posterior distribution of the parameters\n",
    "# Use simulation-based approaches (like the CAMELS simulations you mentioned) to generate many realizations of the observed data and the corresponding model parameters.\n",
    "# Train a neural network to take the observed data as input and output the parameters of the posterior distribution (e.g. mean, variance) for those parameters.\n",
    "# Once the neural network is trained, you can apply it to the actual observed data to obtain estimates of the posterior distributions of the model parameters.\n",
    "\n",
    "# Training arguments\n",
    "train_args = {\n",
    "    \"training_batch_size\": 32, # changed from 4 to 10 as dealing with more sims, want it to be faster for initial testing.\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"stop_after_epochs\": 50, # loss function. waits to see if things improve.\n",
    "    \"validation_fraction\": 0.1,  # creates another split within the training data for validation\n",
    "}\n",
    "\n",
    "# Configure network\n",
    "hidden_features = 20 #neurons\n",
    "num_transforms = 1 #layers\n",
    "\n",
    "\n",
    "nets = [ili.utils.load_nde_sbi(\n",
    "    engine=\"NPE\",\n",
    "    model=\"nsf\",\n",
    "    hidden_features=hidden_features,\n",
    "    num_transforms=num_transforms\n",
    ")]\n",
    "\n",
    "# do ensemble when optimsed first Network\n",
    "'''\n",
    "nets = [\n",
    "    ili.utils.load_nde_sbi(\n",
    "        engine=\"NPE\",# Neural Posterior Estimation\n",
    "        model=\"nsf\",# Neural Spline Flow\n",
    "        hidden_features=hidden_features,# Network width\n",
    "        num_transforms=num_transforms# Network depth\n",
    "    ) for _ in range(3) # for n NNs\n",
    "]\n",
    "'''\n",
    "\n",
    "# Data loader\n",
    "loader = NumpyLoader(\n",
    "\n",
    "    # x = x_all[train_mask]\n",
    "    # theta=theta[train_mask]\n",
    "    # clone - makes new memory allocation for this version of x/theta\n",
    "    # detach - doesnt affect computations on theta that were done previously (not to mess with test/train versions)\n",
    "    x=x_all[train_mask].clone().detach(),\n",
    "    theta=theta[train_mask].clone().detach()\n",
    ")\n",
    "\n",
    "\n",
    "# Runner setup with device specified here\n",
    "runner = InferenceRunner.load(\n",
    "    backend=\"sbi\",\n",
    "    engine=\"NPE\",\n",
    "    prior=prior,\n",
    "    nets= nets,\n",
    "    device=device,  # Device specified in runner, not network\n",
    "    train_args=train_args,\n",
    "    proposal=None,\n",
    "    out_dir=model_out_dir,\n",
    "    name=name\n",
    ")\n",
    "\n",
    "# Run training - 'learn the likelihood'\n",
    "# this is training the neural network which will act like our likelihood!\n",
    "posterior_ensemble, summaries = runner(loader=loader)\n",
    "\n",
    "# process of training:\n",
    "'''\n",
    "- the neural network learns P(θ|x): probability of parameters given observations\n",
    "- uses training data to learn mapping from x → θ\n",
    "- then we validate on held-out portion of training data\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training_batch_size\", train_args[ \"training_batch_size\"])\n",
    "print(\"learning_rate\", train_args[ \"learning_rate\"])\n",
    "print(\"stop_after_epochs\", train_args[ \"stop_after_epochs\"])\n",
    "print(\"validation_fraction\", train_args[ \"validation_fraction\"])\n",
    "print(\"hidden_features\", hidden_features)\n",
    "print(\"num_transforms\", num_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_diagnostics(summaries):\n",
    "    \"\"\"Plot training diagnostics without empty subplots\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))  # Changed to 1 row, 2 columns\n",
    "    \n",
    "    # Loss curves\n",
    "    train_losses = summaries[0]['training_log_probs']\n",
    "    val_losses = summaries[0]['validation_log_probs']\n",
    "    epochs = range(len(train_losses))\n",
    "    \n",
    "    ax1.plot(epochs, train_losses, '-', label='Training', color='blue')\n",
    "    ax1.plot(epochs, val_losses, '--', label='Validation', color='red')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Log probability')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Overfitting gap\n",
    "    gap = np.array(train_losses) - np.array(val_losses)\n",
    "    ax2.plot(epochs, gap, '-', color='purple')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss difference')\n",
    "    ax2.set_title('Overfitting Gap')\n",
    "    ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Use the function\n",
    "fig = plot_training_diagnostics(summaries)\n",
    "plt.savefig(os.path.join(plots_out_dir, f'training_analysis_{name}.png'))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train/validation loss\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "c = list(mcolors.TABLEAU_COLORS)\n",
    "for i, m in enumerate(summaries):\n",
    "    ax.plot(m['training_log_probs'], ls='-', label=f\"{i}_train\", c=c[i])\n",
    "    ax.plot(m['validation_log_probs'], ls='--', label=f\"{i}_val\", c=c[i])\n",
    "ax.set_xlim(0)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Log probability')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will this work or do we have to use it explicitly?\n",
    "x_train=x_all[train_mask].clone().detach(),\n",
    "theta_train=theta[train_mask].clone().detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, SBIRunner returns a custom class instance to be able to pass signature strings\n",
    "# 1. prints our info on model configuration and architecture\n",
    "print(posterior_ensemble.signatures)\n",
    "\n",
    "\n",
    "# 2. choose a random input for training\n",
    "seed_in = 49\n",
    "np.random.seed(seed_in) # set seed for reproducability\n",
    "ind = np.random.randint(len(x_train[0])) # choose observation (random index from training data)\n",
    "\n",
    "# 3. generate posterior samples\n",
    "seed_samp = 32\n",
    "torch.manual_seed(seed_samp)# set seed for reproducability\n",
    "# then, for the chosen training sample (as chosen above in 2.)\n",
    "# generate 1000 samples from the posterior distribution using accept/reject sampling\n",
    "samples = posterior_ensemble.sample(\n",
    "    (1000,), \n",
    "    torch.Tensor(x_train[0][ind]).to(device))\n",
    "\n",
    "# 4. calculate the probability densities for each sample\n",
    "# i.e for each generated sample, calculate how likely it is using learned posterior distribution\n",
    "log_prob = posterior_ensemble.log_prob(\n",
    "    samples, # the generated samples from 3.\n",
    "    torch.Tensor(x_train[0][ind]).to(device) # the chosen observation from 2.\n",
    "    )\n",
    "\n",
    "# convert to numpy so can read easier.\n",
    "samples = samples.cpu().numpy()\n",
    "log_prob = log_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "def plot_posterior_samples_grid(samples, log_prob, param_names, df_info, model_name, train_args):\n",
    "   n_params = len(param_names)\n",
    "   n_cols = 4\n",
    "   n_rows = (n_params + n_cols - 1) // n_cols\n",
    "   \n",
    "   fig = plt.figure(figsize=(20, 5*n_rows))\n",
    "   \n",
    "   # Add main title\n",
    "   fig.suptitle('Posterior Probability Distributions', fontsize=16, y=0.98)\n",
    "   \n",
    "   gs = GridSpec(n_rows, n_cols, figure=fig)\n",
    "   \n",
    "   # Model info text\n",
    "   model_info = (\n",
    "       f\"Model Config:\\n\"\n",
    "       f\"Name: {model_name}\\n\"\n",
    "       f\"Hidden Features: {hidden_features}\\n\"\n",
    "       f\"Num Transforms: {num_transforms}\\n\"\n",
    "       f\"\\nTraining Args:\\n\"\n",
    "       f\"Batch Size: {train_args['training_batch_size']}\\n\"\n",
    "       f\"Learning Rate: {train_args['learning_rate']}\\n\"\n",
    "       f\"Stop After Epochs: {train_args['stop_after_epochs']}\"\n",
    "   )\n",
    "   \n",
    "   fig.text(0.02, 0.96, model_info, \n",
    "            fontsize=8,\n",
    "            bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray'),\n",
    "            verticalalignment='top')\n",
    "   \n",
    "   for i, name in enumerate(param_names):\n",
    "       row = i // n_cols\n",
    "       col = i % n_cols\n",
    "       \n",
    "       ax = fig.add_subplot(gs[row, col])\n",
    "       data = samples[:, i]\n",
    "       param_info = df_info[df_info['ParamName'] == name].iloc[0]\n",
    "       is_log = param_info['LogFlag'] == 1\n",
    "       \n",
    "       if is_log:\n",
    "           ax.hist(data, bins=50, density=True, alpha=0.6)\n",
    "           ax.set_xscale('log')\n",
    "           log_data = np.log10(data)\n",
    "           mean = np.mean(log_data)\n",
    "           std = np.std(log_data)\n",
    "           stats_text = f'Log10 Mean: {mean:.3f}\\nLog10 Std: {std:.3f}'\n",
    "           ax.set_xlabel('Parameter Value (log scale)', fontsize=8)\n",
    "       else:\n",
    "           ax.hist(data, bins=50, density=True, alpha=0.6)\n",
    "           mean = np.mean(data)\n",
    "           std = np.std(data)\n",
    "           stats_text = f'Mean: {mean:.3f}\\nStd: {std:.3f}'\n",
    "           ax.set_xlabel('Parameter Value', fontsize=8)\n",
    "       \n",
    "       ax.set_ylabel('Density', fontsize=8)\n",
    "       \n",
    "       ax.axvline(param_info['MinVal'], color='g', linestyle=':', alpha=0.5, label='Min')\n",
    "       ax.axvline(param_info['MaxVal'], color='g', linestyle=':', alpha=0.5, label='Max')\n",
    "       ax.axvline(param_info['FiducialVal'], color='r', linestyle='--', alpha=0.5, label='Fiducial')\n",
    "       \n",
    "       ax.text(0.02, 0.95, stats_text, transform=ax.transAxes, \n",
    "               verticalalignment='top', fontsize=8, \n",
    "               bbox=dict(facecolor='white', alpha=0.8))\n",
    "       \n",
    "       ax.set_title(f\"{name}\\n{param_info['Description']}\", fontsize=8, pad=5)\n",
    "       ax.tick_params(labelsize=8)\n",
    "       \n",
    "       if i == 0:\n",
    "           ax.legend(loc='upper right', fontsize=8)\n",
    "   \n",
    "   plt.tight_layout()\n",
    "   plt.subplots_adjust(top=0.93)  # Adjusted to make room for main title\n",
    "   return fig\n",
    "\n",
    "# Get all parameter names from df_info\n",
    "param_names = df_info['ParamName'].tolist()\n",
    "\n",
    "# Now try plotting again with the correct parameter names\n",
    "fig = plot_posterior_samples_grid(\n",
    "    samples, \n",
    "    log_prob, \n",
    "    param_names,  # Now contains all 28 parameter names correctly\n",
    "    df_info,\n",
    "    model_name=name,\n",
    "    train_args=train_args\n",
    ")\n",
    "\n",
    "# Save with model config in filename\n",
    "save_name = (f'parameter_posteriors_grid_{name}_'\n",
    "            f'h{hidden_features}_t{num_transforms}_'\n",
    "            f'b{train_args[\"training_batch_size\"]}_'\n",
    "            f'e{train_args[\"stop_after_epochs\"]}.png')\n",
    "\n",
    "os.makedirs(plots_out_dir, exist_ok=True)\n",
    "plt.savefig(os.path.join(plots_out_dir, save_name), \n",
    "            dpi=300, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Evaluation Metrics\n",
    "'''\n",
    "- Coverage: How often true parameters fall within predicted ranges:\n",
    "-- perfect diagonal line means perfect coverage\n",
    "-- points above diaganol means over-confident predictions\n",
    "-- points below diagonal means under-confident\n",
    "-- large deviations from the diaganol means poorly calibrated model\n",
    "\n",
    "- Histogram:\n",
    "-- uniform (straight) distributions of p-values means well-calibrated model\n",
    "-- u-shaped dist: under-confident model\n",
    "-- bell shaped: over confident model\n",
    "\n",
    "- Predictions: Compare model predictions with observations\n",
    "-- True values from your test set (these are your \"observations\")\n",
    "-- Model's predicted distributions for each parameter\n",
    "-- Predicted distributions centered on true values\n",
    "-- Error bar estimates that accurately capture the true values\n",
    "-- Scatter along diagonal: Good predictions\n",
    "-- Systematic offset: Bias in predictions\n",
    "-- Wide spread: High uncertainty\n",
    "-- Clustering in certain regions: Model performs better for some parameter ranges\n",
    "# The predictions are comparing:\n",
    "# The true parameter values used in your simulations (like Omega0, sigma8, etc.) vs\n",
    "# What your neural posterior estimation (NPE) model predicts these values should be\n",
    "# based on the observables (your luminosity functions and/or colors)\n",
    "\n",
    "- TARP: Total Absolute Relative Probability\n",
    "-- lower values indicate better calibration\n",
    "-- comparing across parameters can help identify which are harder to predict\n",
    "-- high TARP values suggest need for model improvement for those parameters\n",
    "\n",
    "'''\n",
    "\n",
    "# to help with labelling to keep track of training args and improvements to model\n",
    "# a configuration string for both filename and plot\n",
    "config_str = (f\"batch{train_args['training_batch_size']}_\"\n",
    "             f\"lr{train_args['learning_rate']}_\"\n",
    "             f\"epochs{train_args['stop_after_epochs']}_\"\n",
    "             f\"h{hidden_features}_t{num_transforms}\")\n",
    "\n",
    "# coverage plots\n",
    "metric = PosteriorCoverage(\n",
    "    num_samples=int(4e3),\n",
    "    sample_method='direct',\n",
    "    labels=cam.labels,\n",
    "    plot_list=[\"coverage\", \"histogram\", \"predictions\", \"tarp\"],\n",
    "    out_dir=plots_out_dir,\n",
    ")\n",
    "\n",
    "# Generate plots\n",
    "figs = metric(\n",
    "    posterior=posterior_ensemble,\n",
    "    x=x_all[test_mask].cpu(),\n",
    "    theta=theta[test_mask, :].cpu(),\n",
    "    signature=f\"coverage_{name}_{config_str}_\"  # Add config to filename\n",
    ")\n",
    "\n",
    "config_text = (\n",
    "    f\"Training Config:\\n\"\n",
    "    f\"Batch Size: {train_args['training_batch_size']}\\n\"\n",
    "    f\"Learning Rate: {train_args['learning_rate']}\\n\"\n",
    "    f\"Epochs: {train_args['stop_after_epochs']}\\n\"\n",
    "    f\"Hidden Features: {hidden_features}\\n\"\n",
    "    f\"Num Transforms: {num_transforms}\"\n",
    ")\n",
    "\n",
    "# Process each figure\n",
    "for i, fig in enumerate(figs):\n",
    "    plt.figure(fig.number)  # Activate the figure\n",
    "    plt.figtext(0.02, 0.98, config_text,\n",
    "                fontsize=8,\n",
    "                bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray'),\n",
    "                verticalalignment='top')\n",
    "    \n",
    "    # Save each figure with type indicator\n",
    "    plot_types = [\"coverage\", \"histogram\", \"predictions\", \"tarp\"]\n",
    "    plt.savefig(os.path.join(plots_out_dir, \n",
    "                f'metric_{plot_types[i]}_{name}_{config_str}.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the metrics as usual\n",
    "metric = PosteriorCoverage(\n",
    "    num_samples=int(4e3),\n",
    "    sample_method='direct',\n",
    "    labels=cam.labels,\n",
    "    plot_list=[\"predictions\"],  # Only need predictions\n",
    "    out_dir=plots_out_dir,\n",
    ")\n",
    "\n",
    "# Get the prediction data\n",
    "figs = metric(\n",
    "    posterior=posterior_ensemble,\n",
    "    x=x_all[test_mask].cpu(),\n",
    "    theta=theta[test_mask, :].cpu(),\n",
    "    signature=f\"predictions_{name}_\"\n",
    ")\n",
    "\n",
    "# Now plot each parameter's predictions separately\n",
    "def plot_individual_predictions(figs, cam_labels, config_text):\n",
    "    \"\"\"Plot true vs predicted values for each parameter separately\"\"\"\n",
    "    \n",
    "    for i, param_name in enumerate(cam_labels):\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        # Copy the prediction plot for this parameter from the original figure\n",
    "        orig_ax = figs[0].axes[i]  # predictions are in first figure\n",
    "        \n",
    "        # Copy over the plot elements\n",
    "        for line in orig_ax.get_lines():\n",
    "            ax.plot(line.get_xdata(), line.get_ydata(), \n",
    "                   color=line.get_color(),\n",
    "                   linestyle=line.get_linestyle(),\n",
    "                   label=line.get_label())\n",
    "            \n",
    "        # Add labels and title\n",
    "        ax.set_xlabel('True Value')\n",
    "        ax.set_ylabel('Predicted Value')\n",
    "        ax.set_title(f'Predictions for {param_name}')\n",
    "        \n",
    "        # Add config info\n",
    "        ax.text(0.02, 0.98, config_text,\n",
    "                transform=ax.transAxes,\n",
    "                fontsize=8,\n",
    "                bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray'),\n",
    "                verticalalignment='top')\n",
    "        \n",
    "        # Save individual plot\n",
    "        plt.savefig(os.path.join(plots_out_dir, \n",
    "                    f'prediction_{param_name}_{name}.png'),\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "# Create the plots\n",
    "plot_individual_predictions(figs, cam.labels, config_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have:\n",
    "# true_values: shape (n_samples, 28)\n",
    "# predicted_means: shape (n_samples, 28)\n",
    "# predicted_stds: shape (n_samples, 28)\n",
    "# parameter_names: list of 28 parameter names\n",
    "\n",
    "fig, axes = plt.subplots(4, 7, figsize=(24, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(28):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot error bars\n",
    "    ax.errorbar(true_values[:, i], predicted_means[:, i],\n",
    "               yerr=predicted_stds[:, i],\n",
    "               fmt='k.', alpha=0.5, capsize=2)\n",
    "    \n",
    "    # Add diagonal line\n",
    "    lims = [\n",
    "        min(ax.get_xlim()[0], ax.get_ylim()[0]),\n",
    "        max(ax.get_xlim()[1], ax.get_ylim()[1])\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k--', alpha=0.5)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(np.mean((true_values[:, i] - predicted_means[:, i])**2))\n",
    "    r2 = np.corrcoef(true_values[:, i], predicted_means[:, i])[0,1]**2\n",
    "    \n",
    "    # Add metrics box\n",
    "    ax.text(0.05, 0.95, f'RMSE = {rmse:.2f}\\nR² = {r2:.2f}',\n",
    "            transform=ax.transAxes, bbox=dict(facecolor='white'))\n",
    "    \n",
    "    ax.set_title(parameter_names[i])\n",
    "    ax.set_xlabel('True')\n",
    "    ax.set_ylabel('Inferred')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
