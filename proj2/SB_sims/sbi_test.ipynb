{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from ili.dataloaders import NumpyLoader\n",
    "from ili.inference import InferenceRunner\n",
    "from ili.validation.metrics import PosteriorCoverage\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import joblib\n",
    "sys.path.append(\"/disk/xray15/aem2/camels/proj2\")\n",
    "from setup_params_alice import *\n",
    "\n",
    "# note from Alice:\n",
    "# in Chris' code, I think he loads in photometry directly from CAMELS sims, gets galaxies then gets photometry for flux/lums\n",
    "# I only have flux lums so can not use his get_x / get_theta versions that rely on the camels method.\n",
    "\n",
    "\n",
    "# safe name for passing in and using for naming paths/directories without underscores.  see more below (get_colour_dir_name)\n",
    "def get_safe_name(name, filter_system_only=False):\n",
    "    \"\"\"\n",
    "    Convert string to path-safe version and/or extract filter system.\n",
    "    \"\"\"\n",
    "    safe_name = name.replace(' ', '_')\n",
    "    if filter_system_only:\n",
    "        return safe_name.split('_')[0]\n",
    "    return safe_name\n",
    "\n",
    "def load_uvlf_data(base_dir, start_group=0, end_group=49, redshift_dict=None, filters=None):\n",
    "    \"\"\"\n",
    "    Load UVLF data from txt files\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    # Default to GALEX filters if none specified\n",
    "    filters = filters or [\"GALEX FUV\", \"GALEX NUV\"]\n",
    "    redshift_dict = redshift_dict or {'044': {'redshift': 2.00, 'label': 'z2.0'}}\n",
    "    \n",
    "    for group_num in range(start_group, end_group + 1):\n",
    "        sim_name = f\"SB28_{group_num}\"\n",
    "        group_data = []\n",
    "        \n",
    "        for snap, redshift_info in redshift_dict.items():\n",
    "            for band in filters:\n",
    "                # Construct file path using same structure as when saving\n",
    "                filter_system = get_safe_name(band, filter_system_only=True)\n",
    "                file_name = f\"UVLF_{sim_name}_{get_safe_name(band)}_{get_safe_name(redshift_info['label'])}_attenuated.txt\"\n",
    "                file_path = os.path.join(base_dir, \"LFs\", \"attenuated\", filter_system, \n",
    "                                       get_safe_name(redshift_info['label']), file_name)\n",
    "                \n",
    "                try:\n",
    "                    # Load the UVLF data\n",
    "                    df = pd.read_csv(file_path, sep='\\t')\n",
    "                    # Append phi values (log number density)\n",
    "                    group_data.extend(df['phi'].values)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_path}: {e}\")\n",
    "                    return None\n",
    "                    \n",
    "        data.append(group_data)\n",
    "    \n",
    "    return np.array(data)\n",
    "\n",
    "def setup_sbi(input_dir, start_group=0, end_group=49, redshift_dict=None):\n",
    "    \"\"\"Set up and run SBI\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Device:\", device)\n",
    "    \n",
    "    # Load UVLF data\n",
    "    x_all = load_uvlf_data(\n",
    "        input_dir, \n",
    "        start_group=start_group,\n",
    "        end_group=end_group,\n",
    "        redshift_dict=redshift_dict\n",
    "    )\n",
    "    \n",
    "    if x_all is None:\n",
    "        print(\"Failed to load data\")\n",
    "        return\n",
    "    \n",
    "    # Initialize model parameters\n",
    "    name = \"SB28_GALEX_UVLF_test\"\n",
    "    hidden_features = 30\n",
    "    num_transforms = 4\n",
    "    \n",
    "    # Normalize data\n",
    "    norm = Normalizer()\n",
    "    x_all = torch.tensor(\n",
    "        norm.fit_transform(X=x_all),\n",
    "        dtype=torch.float32,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Save normalizer\n",
    "    joblib.dump(norm, f'/disk/xray15/aem2/models/{name}_scaler.save')\n",
    "    \n",
    "    # Setup test/train split\n",
    "    test_mask = np.random.rand(len(x_all)) > 0.9\n",
    "    np.savetxt('/disk/xray15/aem2/data/test_mask_galex.txt', test_mask, fmt='%i')\n",
    "    \n",
    "    # Initialize networks\n",
    "    nets = [\n",
    "        ili.utils.load_nde_sbi(\n",
    "            engine=\"NPE\",\n",
    "            model=\"nsf\", \n",
    "            hidden_features=hidden_features, \n",
    "            num_transforms=num_transforms\n",
    "        ) for _ in range(3)\n",
    "    ]\n",
    "    \n",
    "    # Setup training parameters\n",
    "    train_args = {\n",
    "        \"training_batch_size\": 4,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        'stop_after_epochs': 20\n",
    "    }\n",
    "    \n",
    "    # Initialize data loader\n",
    "    loader = NumpyLoader(\n",
    "        x=x_all[~test_mask],\n",
    "        theta=torch.tensor(theta[~test_mask, :], device=device)\n",
    "    )\n",
    "    \n",
    "    # Setup and run inference\n",
    "    runner = InferenceRunner.load(\n",
    "        backend=\"sbi\",\n",
    "        engine=\"NPE\",\n",
    "        prior=prior,\n",
    "        nets=nets,\n",
    "        device=device,\n",
    "        train_args=train_args,\n",
    "        proposal=None,\n",
    "        out_dir=\"models/\",\n",
    "        name=name,\n",
    "    )\n",
    "    \n",
    "    posterior_ensemble, summaries = runner(loader=loader)\n",
    "    \n",
    "    # Generate coverage plots\n",
    "    metric = PosteriorCoverage(\n",
    "        num_samples=int(4e3),\n",
    "        sample_method='direct',\n",
    "        labels=param_labels,\n",
    "        plot_list=[\"coverage\", \"histogram\", \"predictions\", \"tarp\"],\n",
    "        out_dir=\"../plots/\",\n",
    "    )\n",
    "    \n",
    "    fig = metric(\n",
    "        posterior=posterior_ensemble,\n",
    "        x=x_all[test_mask].cpu(),\n",
    "        theta=theta[test_mask, :].cpu(),\n",
    "        signature=f\"coverage_{name}_\",\n",
    "    )\n",
    "    \n",
    "    return posterior_ensemble, summaries\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with just z=2.0\n",
    "    redshift_test = {'044': {'redshift': 2.00, 'label': 'z2.0'}}\n",
    "    \n",
    "    # Run SBI\n",
    "    posterior, summaries = setup_sbi(\n",
    "        input_dir=\"/disk/xray15/aem2/data/28pams/IllustrisTNG/SB\",\n",
    "        start_group=0,\n",
    "        end_group=49,\n",
    "        redshift_dict=redshift_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
