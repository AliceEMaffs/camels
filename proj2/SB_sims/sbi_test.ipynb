{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Concepts\n",
    "'''\n",
    "1. Forward problem: θ → x (simulation)\n",
    "2. Inverse problem: x → θ (what we're solving)\n",
    "3. Posterior: P(θ|x) probability distribution over parameters\n",
    "4. Prior: Initial assumptions about parameter ranges\n",
    "'''\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# seaparate into train and test set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as mcolors\n",
    "import torch\n",
    "from torch.distributions import Uniform, ExpTransform, TransformedDistribution #, AffineTransform\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import joblib\n",
    "\n",
    "import ili\n",
    "from ili.dataloaders import NumpyLoader\n",
    "from ili.inference import InferenceRunner\n",
    "from ili.validation.metrics import PosteriorCoverage, PlotSinglePosterior\n",
    "\n",
    "from sbi.utils.user_input_checks import process_prior\n",
    "\n",
    "sys.path.append(\"/disk/xray15/aem2/camels/proj2\")\n",
    "from setup_params_alice import *\n",
    "from priors_SB import initialise_priors_SB28\n",
    "\n",
    "# parameters\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = \"IllustrisTNG\"\n",
    "spec_type = \"attenuated\"\n",
    "sps = \"BC03\"\n",
    "snap = [\"044\"]\n",
    "# 12 bins!\n",
    "n_bins_lf = 13\n",
    "n_bins_colour = 13\n",
    "bands = \"all\" # or just GALEX?\n",
    "colours = False  # just for now, lets do UVLF\n",
    "luminosity_functions = True\n",
    "name = f\"{model}_{bands}_{sps}_{spec_type}_{n_bins_lf}\"#_{n_bins_colour}\"\n",
    "\n",
    "# initialize CAMELS and load parameter info using camels.py\n",
    "cam = camels(model=model, sim_set='SB28')\n",
    "\n",
    "# trys to use Chris method here, get_x, get_theta directly from photometry files instead of intermediate txt files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter info file (df_info) is used for defining priors\n",
    "# the actual parameter values come from the camels class which reads CosmoAstroSeed_IllustrisTNG_L25n256_SB28.txt\n",
    "\n",
    "#  parameters defined here: /disk/xray15/aem2/data/28pams/IllustrisTNG/SB/CosmoAstroSeed_IllustrisTNG_L25n256_SB28.txt which is used for theta\n",
    "df_pars = pd.read_csv('/disk/xray15/aem2/data/28pams/IllustrisTNG/SB/CosmoAstroSeed_IllustrisTNG_L25n256_SB28.txt', delim_whitespace=True)\n",
    "print(df_pars)\n",
    "\n",
    "\n",
    "# prior values come from this:\n",
    "df_info = pd.read_csv(\"/disk/xray15/aem2/data/28pams/Info_IllustrisTNG_L25n256_28params.txt\")\n",
    "print(df_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = df_pars.iloc[:, 1:29].to_numpy()  # excluding 'name' column and 'seed' column\n",
    "\n",
    "print(theta)\n",
    "print(theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column names:\")\n",
    "print(df_pars.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first one (omega0) to see shape of prior:\n",
    "plt.hist(theta[:, 24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  reference from setup_params_alice.py\n",
    "def calc_df(_x, volume, massBinLimits):\n",
    "    hist, _dummy = np.histogram(_x, bins=massBinLimits)\n",
    "    hist = np.float64(hist)\n",
    "    phi = (hist / volume) / (massBinLimits[1] - massBinLimits[0])\n",
    "\n",
    "    phi_sigma = (np.sqrt(hist) / volume) / (\n",
    "        massBinLimits[1] - massBinLimits[0]\n",
    "    )  # Poisson errors\n",
    "\n",
    "    return phi, phi_sigma, hist\n",
    "\n",
    "def get_luminosity_function(\n",
    "    photo,\n",
    "    filt,\n",
    "    lo_lim,\n",
    "    hi_lim,\n",
    "    n_bins=15,\n",
    "    mask=None,\n",
    "):\n",
    "    h = 0.6711\n",
    "    if mask is None:\n",
    "        mask = np.ones(len(photo[filt]), dtype=bool)\n",
    "\n",
    "    binLimits = np.linspace(lo_lim, hi_lim, n_bins)\n",
    "    phi, phi_sigma, hist = calc_df(photo[filt][mask], (25 / h) ** 3, binLimits)\n",
    "    phi[phi == 0.0] = 1e-6 + np.random.rand() * 1e-7\n",
    "    phi = np.log10(phi)\n",
    "    return phi, phi_sigma, hist, binLimits\n",
    "\n",
    "def get_photometry(\n",
    "    sim_name=\"LH_0\",\n",
    "    spec_type=\"attenuated\",\n",
    "    snap=\"090\",\n",
    "    sps=\"BC03\",\n",
    "    model=\"IllustrisTNG\",\n",
    "    photo_dir=(\"/disk/xray15/aem2/data/28pams/IllustrisTNG/photometry\"),\n",
    "    filters=[\n",
    "        \"SLOAN/SDSS.u\",\n",
    "        \"SLOAN/SDSS.g\",\n",
    "        \"SLOAN/SDSS.r\",\n",
    "        \"SLOAN/SDSS.i\",\n",
    "        \"SLOAN/SDSS.z\",\n",
    "        \"GALEX FUV\",\n",
    "        \"GALEX NUV\",\n",
    "    ],\n",
    "):\n",
    "    photo_file = f\"{photo_dir}/{model}_{sim_name}_photometry.hdf5\"\n",
    "    photo = {}\n",
    "    with h5py.File(photo_file, \"r\") as hf:\n",
    "        for filt in filters:\n",
    "            photo[filt] = hf[\n",
    "                f\"snap_{snap}/{sps}/photometry/luminosity/{spec_type}/{filt}\"\n",
    "            ][:]\n",
    "            photo[filt] *= unyt_quantity.from_string(\"1 erg/s/Hz\") \n",
    "            photo[filt] = lnu_to_absolute_mag(photo[filt])\n",
    "\n",
    "    return photo\n",
    "'''\n",
    "def get_photometry_SB(\n",
    "    sim_name=\"SB28_0\",\n",
    "    spec_type=\"attenuated\",\n",
    "    snap=\"044\",\n",
    "    sps=\"BC03\",\n",
    "    model=\"IllustrisTNG\",\n",
    "    photo_dir=\"/disk/xray15/aem2/data/28pams/IllustrisTNG/SB/photometry\",\n",
    "    filters=[\"GALEX FUV\", \"GALEX NUV\"],\n",
    "):\n",
    "    photo = {}\n",
    "    with h5py.File(f\"{photo_dir}/alice_galex.h5\", \"r\") as hf:\n",
    "        for filt in filters:\n",
    "            path = f\"{sim_name}/snap_{snap}/{sps}/photometry/luminosity/{spec_type}/{filt}\"\n",
    "            photo[filt] = hf[path][:]\n",
    "            # comment out if data is already in desired format, remove conversion if not needed. in Chris function get_photometry so keep here.\n",
    "            photo[filt] *= unyt_quantity.from_string(\"1 erg/s/Hz\")\n",
    "            photo[filt] = lnu_to_absolute_mag(photo[filt])\n",
    "    return photo\n",
    "\n",
    "def get_theta_SB(model=\"IllustrisTNG\", device=\"cuda\"):\n",
    "    # theta is the number of simulation parameters so 28\n",
    "    cam = camels(model=model, sim_set='SB28')\n",
    "    theta = np.array([\n",
    "        cam.params['Omega0'].values,              # Omega0\n",
    "        cam.params['sigma8'].values,              # sigma8\n",
    "        cam.params['WindEnergyIn1e51erg'].values, # Wind Energy in 1e51 erg\n",
    "        cam.params['RadioFeedbackFactor'].values,  # Radio Feedback Factor\n",
    "        cam.params['VariableWindVelFactor'].values, # Variable Wind Velocity Factor\n",
    "        cam.params['RadioFeedbackReiorientationFactor'].values, # Radio Feedback Reorientation Factor\n",
    "        cam.params['OmegaBaryon'].values,         # Omega Baryon\n",
    "        cam.params['HubbleParam'].values,         # Hubble Parameter\n",
    "        cam.params['n_s'].values,                 # n_s\n",
    "        cam.params['MaxSfrTimescale'].values,     # Max SFR Timescale\n",
    "        cam.params['FactorForSofterEQS'].values,  # Factor for Softer EQS\n",
    "        cam.params['IMFslope'].values,            # IMF slope\n",
    "        cam.params['SNII_MinMass_Msun'].values,   # SNII Minimum Mass (Msun)\n",
    "        cam.params['ThermalWindFraction'].values, # Thermal Wind Fraction\n",
    "        cam.params['VariableWindSpecMomentum'].values, # Variable Wind Specific Momentum\n",
    "        cam.params['WindFreeTravelDensFac'].values, # Wind Free Travel Density Factor\n",
    "        cam.params['MinWindVel'].values,          # Minimum Wind Velocity\n",
    "        cam.params['WindEnergyReductionFactor'].values, # Wind Energy Reduction Factor\n",
    "        cam.params['WindEnergyReductionMetallicity'].values, # Wind Energy Reduction Metallicity\n",
    "        cam.params['WindEnergyReductionExponent'].values, # Wind Energy Reduction Exponent\n",
    "        cam.params['WindDumpFactor'].values,      # Wind Dump Factor\n",
    "        cam.params['SeedBlackHoleMass'].values,   # Seed Black Hole Mass\n",
    "        cam.params['BlackHoleAccretionFactor'].values, # Black Hole Accretion Factor\n",
    "        cam.params['BlackHoleEddingtonFactor'].values, # Black Hole Eddington Factor\n",
    "        cam.params['BlackHoleFeedbackFactor'].values, # Black Hole Feedback Factor\n",
    "        cam.params['BlackHoleRadiativeEfficiency'].values, # Black Hole Radiative Efficiency\n",
    "        cam.params['QuasarThreshold'].values,     # Quasar Threshold\n",
    "        cam.params['QuasarThresholdPower'].values # Quasar Threshold Power\n",
    "    ]).T\n",
    "    \n",
    "    return torch.tensor(theta, dtype=torch.float32, device=device)\n",
    "    \n",
    "\n",
    "def get_x_SB( # get colours or LFs\n",
    "    # x.shape= (no. sims, no. bins*features) \n",
    "\n",
    "        # 2 GALEX filters (FUV, NUV)\n",
    "        # Each filter gets n_bins_lf (12) bins\n",
    "        # 2 filters * 12 bins = 24 features\n",
    "        # 1 color (FUV-NUV)\n",
    "        # Gets n_bins_colour (9) bins\n",
    "        # 1 color * 9 bins = 9 features\n",
    "\n",
    "    # Total: 24 + 9 = 33 features per simulation with colours & UVLF but with just UVLF its 24\n",
    "     \n",
    "    spec_type=\"attenuated\",\n",
    "    snap=\"044\",\n",
    "    sps=\"BC03\",\n",
    "    luminosity_functions=True,\n",
    "    colours=False, # true for later, lets do UVLF first.\n",
    "    model=\"IllustrisTNG\",\n",
    "    photo_dir=\"/disk/xray15/aem2/data/28pams/IllustrisTNG/SB/photometry\",\n",
    "    n_bins_lf=13,\n",
    "    n_bins_colour=13,\n",
    "):\n",
    "    if isinstance(snap, str):\n",
    "        snap = [snap]\n",
    "\n",
    "    x = [[] for _ in range(2048)]  # For SB28 simulations\n",
    "\n",
    "    for SB28_ in range(2048):\n",
    "        try:\n",
    "            for snp in snap:\n",
    "                photo = get_photometry_SB(\n",
    "                    sim_name=f\"SB28_{SB28_}\",\n",
    "                    spec_type=spec_type,\n",
    "                    snap=snp,\n",
    "                    sps=sps,\n",
    "                    model=model,\n",
    "                    photo_dir=photo_dir,\n",
    "                )\n",
    "\n",
    "                if luminosity_functions:\n",
    "                    for filt, lo_lim, hi_lim in zip(\n",
    "                        [\"GALEX FUV\", \"GALEX NUV\"],\n",
    "                        [-20.5, -20.5],\n",
    "                        [-15, -15],\n",
    "                    ):\n",
    "                        phi = get_luminosity_function(\n",
    "                            photo, filt, lo_lim, hi_lim, n_bins=n_bins_lf\n",
    "                        )[0]\n",
    "                        x[SB28_].append(phi)\n",
    "\n",
    "                if colours:\n",
    "                    binLimsColour = np.linspace(-0.5, 3.5, n_bins_colour)\n",
    "                    color = photo[\"GALEX FUV\"] - photo[\"GALEX NUV\"]\n",
    "                    color_dist = np.histogram(color, binLimsColour, density=True)[0]\n",
    "                    x[SB28_].append(color_dist)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing simulation {SB28_}: {e}\")\n",
    "            x[SB28_] = None\n",
    "\n",
    "    # Remove any failed simulations\n",
    "    x = [xi for xi in x if xi is not None]\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def get_theta_x_SB(\n",
    "    spec_type=\"attenuated\",\n",
    "    snap=\"044\",\n",
    "    sps=\"BC03\",\n",
    "    model=\"IllustrisTNG\",\n",
    "    device=\"cuda\",\n",
    "    **kwargs,\n",
    "):\n",
    "    x = get_x_SB(spec_type=spec_type, snap=snap, sps=sps, model=model, **kwargs)\n",
    "    theta = get_theta_SB(model=model, device=device)\n",
    "    \n",
    "    # Convert x list to proper array format\n",
    "    x_array = np.array([np.hstack(_x) for _x in x])\n",
    "    return theta, x_array\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    theta, x = get_theta_x_SB()\n",
    "    print(theta.shape, x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the priors and data\n",
    "prior = initialise_priors_SB28(\n",
    "    df=df_info, \n",
    "    device=device,\n",
    "    astro=True,\n",
    "    dust=False  # no dust for testing. set to False to only get the 28 model parameters.\n",
    "    # with dust = True, prior has 32 dimensions (28 parameters + 4 dust parameters) \n",
    ")\n",
    "\n",
    "theta, x = get_theta_x_SB(\n",
    "    spec_type=spec_type,\n",
    "    snap=snap,\n",
    "    sps=sps,\n",
    "    model=model,\n",
    "    device=device,\n",
    "    n_bins_lf=n_bins_lf,\n",
    "    n_bins_colour=n_bins_colour,\n",
    "    photo_dir=\"/disk/xray15/aem2/data/28pams/IllustrisTNG/SB/photometry\"\n",
    ")\n",
    "\n",
    "# process the data\n",
    "x_all = np.array([np.hstack(_x) for _x in x])\n",
    "x_all = torch.tensor(x_all, dtype=torch.float32, device=device)\n",
    "\n",
    "print(\"Theta shape:\", theta.shape)\n",
    "print(\"X shape:\", x_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask for test fraction (10% currently)\n",
    "def create_test_mask(n_sims=2048, test_fraction=0.1, random_seed=42):\n",
    "    \"\"\"\n",
    "    Create a test mask similar to the LH one but for SB 2048 simulations.\n",
    "    \n",
    "    Args:\n",
    "        n_sims: Number of simulations (2048 for SB28)\n",
    "        test_fraction: Fraction of simulations to use for testing (0.1 = 10%)\n",
    "        random_seed: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Boolean mask where True indicates test set\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    test_mask = np.random.rand(n_sims) > (1 - test_fraction)\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"Total simulations: {n_sims}\")\n",
    "    print(f\"Test set size: {test_mask.sum()}\")\n",
    "    print(f\"Training set size: {(~test_mask).sum()}\")\n",
    "    print(f\"Test fraction: {test_mask.sum() / n_sims:.3f}\")\n",
    "    \n",
    "    # Save the mask\n",
    "    save_path = \"/disk/xray15/aem2/data/28pams/IllustrisTNG/SB/test/test_mask_SB28.txt\"\n",
    "    np.savetxt(save_path, test_mask.astype(int), fmt='%i')\n",
    "    \n",
    "    return test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Move data to GPU as early as possible\n",
    "x_all = x_all.to(device)\n",
    "x_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.tensor(theta, dtype=torch.float32, device=device)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN values and normalize while on GPU\n",
    "x_all_cpu = x_all.cpu().numpy()  # Only move to CPU when necessary for sklearn\n",
    "x_all_cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data shape before processing:\", x_all_cpu.shape)\n",
    "print(\"Number of values:\",(x_all_cpu).sum())\n",
    "print(\"Number of NaN values:\", np.isnan(x_all_cpu).sum())\n",
    "print(\"Number of infinite values:\", np.isinf(x_all_cpu).sum())\n",
    "\n",
    "# how many nan values are there? if they are all nan something has gone horribly wrong.\n",
    "# this looks better - 18th Nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get rid of NaN/inf values, replace with small random noise\n",
    "nan_mask = np.isnan(x_all_cpu) | np.isinf(x_all_cpu)\n",
    "nan_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if nan_mask.any():\n",
    "    x_all_cpu[nan_mask] = np.random.rand(np.sum(nan_mask)) * 1e-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data shape before processing:\", x_all_cpu.shape)\n",
    "print(\"Number of NaN values:\", np.isnan(x_all_cpu).sum())\n",
    "print(\"Number of infinite values:\", np.isinf(x_all_cpu).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize\n",
    "norm = Normalizer()\n",
    "x_all_normalized = norm.fit_transform(x_all_cpu)\n",
    "x_all = torch.tensor(x_all_normalized, dtype=torch.float32, device=device)\n",
    "x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save normalizer\n",
    "joblib.dump(norm, f'/disk/xray15/aem2/data/28pams/IllustrisTNG/SB/models/{name}_scaler.save')\n",
    "\n",
    "# Print final check\n",
    "print(\"Any NaN in normalized data:\", torch.isnan(x_all).any().item())\n",
    "print(\"Any inf in normalized data:\", torch.isinf(x_all).any().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make test mask\n",
    "test_mask = create_test_mask() # 10% testing\n",
    "test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = ~test_mask # 90% for training\n",
    "train_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original\n",
    "\n",
    "hidden_features = 30\n",
    "num_transforms = 4\n",
    "nets = [\n",
    "    # ili.utils.load_nde_sbi(\n",
    "    #     engine=\"NLE\", model=\"maf\", hidden_features=50, num_transforms=5\n",
    "    # ),\n",
    "    ili.utils.load_nde_sbi(\n",
    "        engine=\"NPE\",\n",
    "        model=\"nsf\", hidden_features=hidden_features, num_transforms=num_transforms\n",
    "    ),\n",
    "    '''\n",
    "\n",
    "    ili.utils.load_nde_sbi(\n",
    "        engine=\"NPE\",\n",
    "        model=\"nsf\", hidden_features=hidden_features, num_transforms=num_transforms\n",
    "    ),\n",
    "    ili.utils.load_nde_sbi(\n",
    "        engine=\"NPE\",\n",
    "        model=\"nsf\", hidden_features=hidden_features, num_transforms=num_transforms\n",
    "    ),\n",
    "    # ili.utils.load_nde_sbi(\n",
    "    #     engine=\"NPE\",\n",
    "    #     model=\"nsf\", hidden_features=hidden_features, num_transforms=num_transforms\n",
    "    # ),\n",
    "    # ili.utils.load_nde_lampe(model=\"nsf\", device=device, hidden_features=20, num_transforms=2), \n",
    "    # ili.utils.load_nde_lampe(model=\"nsf\", device=device, hidden_features=20, num_transforms=2), \n",
    "    '''\n",
    "]\n",
    "print(nets)\n",
    "\n",
    "\n",
    "train_args = {\"training_batch_size\": 4, \"learning_rate\": 5e-4, 'stop_after_epochs': 20}\n",
    "print(train_args)\n",
    "\n",
    "\n",
    "loader = NumpyLoader(\n",
    "    x=x_all[~test_mask],\n",
    "    # theta=torch.tensor(theta[~test_mask], device=device)\n",
    "    theta=torch.tensor(theta[~test_mask, :], device=device)\n",
    ")\n",
    "print(loader)\n",
    "\n",
    "runner = InferenceRunner.load(\n",
    "    backend=\"sbi\",  #'sbi', # 'lampe',\n",
    "    engine=\"NPE\",\n",
    "    prior=prior,\n",
    "    nets=nets,\n",
    "    device=device,\n",
    "    train_args=train_args,\n",
    "    proposal=None,\n",
    "    # embedding_net=None,\n",
    "    out_dir=\"models/\",\n",
    "    name=name,\n",
    ")\n",
    "print(runner)\n",
    "\n",
    "posterior_ensemble, summaries = runner(loader=loader)\n",
    "print(posterior_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure network properly\n",
    "hidden_features = 30\n",
    "num_transforms = 4\n",
    "net = ili.utils.load_nde_sbi(\n",
    "    engine=\"NPE\",                       # Neural Posterior Estimation\n",
    "    model=\"nsf\",                        # Neural Spline Flow\n",
    "    hidden_features=hidden_features,    # Network width\n",
    "    num_transforms=num_transforms,      # Network depth\n",
    "    # Remove device parameter as it's not allowed\n",
    ")\n",
    "\n",
    "# \n",
    "'''\n",
    "Total simulations: 2048\n",
    "Test set size: 203\n",
    "Training set size: 1845\n",
    "Test fraction: 0.099\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Training arguments\n",
    "train_args = {\n",
    "    \"training_batch_size\": 10, # changed from 4 to 10 as dealing with more sims, want it to be faster for initial testing.\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"stop_after_epochs\": 20\n",
    "}\n",
    "\n",
    "x_train=x_all[train_mask].clone().detach(),\n",
    "theta_train=theta[train_mask].clone().detach()\n",
    "\n",
    "# Data loader\n",
    "loader = NumpyLoader(\n",
    "\n",
    "    # x = x_all[train_mask]\n",
    "    # theta=theta[train_mask]\n",
    "    x_train=x_train,#x_all[train_mask].clone().detach(),\n",
    "    theta_train=theta_train#theta[train_mask].clone().detach()\n",
    ")\n",
    "\n",
    "# Runner setup with device specified here\n",
    "runner = InferenceRunner.load(\n",
    "    backend=\"sbi\",\n",
    "    engine=\"NPE\",\n",
    "    prior=prior,\n",
    "    nets=[net],\n",
    "    device=device,  # Device specified in runner, not network\n",
    "    train_args=train_args,\n",
    "    proposal=None,\n",
    "    out_dir=\"/disk/xray15/aem2/data/28pams/IllustrisTNG/SB/models/\",\n",
    "    name=name\n",
    ")\n",
    "\n",
    "# Run training\n",
    "posterior_ensemble, summaries = runner(loader=loader)\n",
    "\n",
    "# process of training:\n",
    "'''\n",
    "- the neural network learns P(θ|x): probability of parameters given observations\n",
    "- uses training data to learn mapping from x → θ\n",
    "- then we validate on held-out portion of training data\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train/validation loss\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "c = list(mcolors.TABLEAU_COLORS)\n",
    "for i, m in enumerate(summaries):\n",
    "    ax.plot(m['training_log_probs'], ls='-', label=f\"{i}_train\", c=c[i])\n",
    "    ax.plot(m['validation_log_probs'], ls='--', label=f\"{i}_val\", c=c[i])\n",
    "ax.set_xlim(0)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Log probability')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Coverage plots for each model\n",
    "\"\"\"\n",
    "metric = PosteriorCoverage(\n",
    "    num_samples=int(4e3),\n",
    "    sample_method='direct',\n",
    "    # sample_method=\"slice_np_vectorized\",\n",
    "    # sample_params={'num_chains': 1},\n",
    "    # sample_method=\"vi\",\n",
    "    # sample_params={\"dist\": \"maf\", \"n_particles\": 32, \"learning_rate\": 1e-2},\n",
    "    labels=cam.labels,\n",
    "    plot_list=[\"coverage\", \"histogram\", \"predictions\", \"tarp\"],\n",
    "    out_dir=\"/disk/xray15/aem2/plots/28pams/IllustrisTNG/SB/test/sbi_plots\",\n",
    ")\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Evaluation Metrics\n",
    "'''\n",
    "- Coverage: How often true parameters fall within predicted ranges\n",
    "- TARP: Total Absolute Relative Probability\n",
    "- Predictions: Compare model predictions with observations\n",
    "- Parameter recovery: Compare predicted vs true parameters\n",
    "'''\n",
    "fig = metric(\n",
    "    posterior=posterior_ensemble,\n",
    "    x=x_all[test_mask].cpu(),\n",
    "    # theta=theta[test_mask].cpu(),\n",
    "    theta=theta[test_mask, :].cpu(),\n",
    "    signature=f\"coverage_{name}_\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, SBIRunner returns a custom class instance to be able to pass signature strings\n",
    "# This class has simply for attributes a NeuralPosteriorEstimate and a string list \n",
    "print(posterior_ensemble.signatures)\n",
    "\n",
    "# choose a random input\n",
    "seed_in = 49\n",
    "np.random.seed(seed_in)\n",
    "ind = np.random.randint(len(theta_train))\n",
    "\n",
    "# generate samples from the posterior using accept/reject sampling\n",
    "seed_samp = 32\n",
    "torch.manual_seed(seed_samp)\n",
    "samples = posterior_ensemble.sample((2048,), torch.Tensor(x_train[ind]).to(device))\n",
    "\n",
    "# calculate the log_prob for each sample\n",
    "log_prob = posterior_ensemble.log_prob(samples, torch.Tensor(x_train[ind]).to(device))\n",
    "\n",
    "samples = samples.cpu().numpy()\n",
    "log_prob = log_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the posterior samples and the true value for all pairs of theta values\n",
    "fig, axs = plt.subplots(5, 5, figsize=(15, 15))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i != j:\n",
    "            axs[i, j].plot(theta_train[ind, i], theta_train[ind, j], 'r+', markersize=10, label='true')\n",
    "            im = axs[i, j].scatter(samples[:, i], samples[:, j], c=log_prob, s=4, label='samples', cmap='viridis')\n",
    "            axs[i, j].set_xlabel(f'$\\\\theta_{i}$')\n",
    "            axs[i, j].set_ylabel(f'$\\\\theta_{j}$')\n",
    "            axs[i, j].legend()\n",
    "        else:\n",
    "            axs[i, j].axis('off')\n",
    "\n",
    "# Add a color bar for log probability\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax, label='log probability')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('True values are marked with red pluses, and the pairs of theta values are plotted against each other.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
