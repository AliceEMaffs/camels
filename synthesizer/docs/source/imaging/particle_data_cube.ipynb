{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Spectral Data Cubes from Galaxy Particle distributions\n",
    "\n",
    "In this example we show how to create a spectral data cube from stellar particles. For this purpose we need a stellar distribution and a galaxy. The first section will handle this setup using a CAMELS galaxy, feel free to skip over this section to get to the spectral data cube synthesis as the process is well documented elsewhere (e.g. the CAMELS [docs](../cosmo/cosmo_example.ipynb)).\n",
    "\n",
    "## The setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "from synthesizer.grid import Grid\n",
    "from synthesizer.imaging import SpectralCube\n",
    "from synthesizer.kernel_functions import Kernel\n",
    "from synthesizer.load_data.load_camels import load_CAMELS_IllustrisTNG\n",
    "from unyt import kpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do anything we need an SPS grid from which to derive spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid\n",
    "grid_name = \"test_grid\"\n",
    "grid_dir = \"../../../tests/test_grid/\"\n",
    "grid = Grid(grid_name, grid_dir=grid_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will use one of the CAMELS galaxies from the test data. For details on making your own galaxies see [the particle galaxy docs](../galaxies/galaxy_obj.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_start = time.time()\n",
    "\n",
    "# Create galaxy object\n",
    "gal = load_CAMELS_IllustrisTNG(\n",
    "    \"../../../tests/data/\",\n",
    "    snap_name=\"camels_snap.hdf5\",\n",
    "    fof_name=\"camels_subhalo.hdf5\",\n",
    "    physical=True,\n",
    ")[0]\n",
    "\n",
    "print(\"Galaxy created, took:\", time.time() - galaxy_start)\n",
    "\n",
    "print(f\"Galaxy has {gal.stars.nstars} stellar particles\")\n",
    "print(f\"Galaxy gas {gal.gas.nparticles} gas particles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a galaxy we can derive spectra. For this example we'll use reprocessed spectra (see the spectra [docs](../sed.ipynb)). Once we have the spectra we will convert from spectral luminosity density to spectral flux density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_start = time.time()\n",
    "\n",
    "# Calculate the stellar rest frame SEDs for all particles in erg / s / Hz\n",
    "sed = gal.stars.get_particle_spectra_reprocessed(grid)\n",
    "\n",
    "# Calculate the observed SED in nJy\n",
    "sed.get_fnu(cosmo, gal.redshift)\n",
    "\n",
    "print(\"Spectra created, took:\", time.time() - spectra_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Data Cube Creation\n",
    "\n",
    "We now have most of the ingredients we need to generate a spectral data cube from our galaxy. The only parts that are missing are the wavelength array of our spectral data cube, its resolution and FOV, and a kernel for smoothing particles over. We'll define these below and move on to making the spectral data cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the width of the image\n",
    "width = 30 * kpc\n",
    "\n",
    "# Define image resolution (here we arbitrarily set it to 100\n",
    "# pixels along an axis)\n",
    "resolution = width / 200\n",
    "\n",
    "# Define the wavelength array\n",
    "lam = np.linspace(10**3.5, 10**4.5, 1000)\n",
    "\n",
    "print(\n",
    "    \"Data cube spatial width is %.2f kpc with a %.2f kpc spaxel resolution\"\n",
    "    % (width.value, resolution.value)\n",
    ")\n",
    "\n",
    "# Get the SPH kernel\n",
    "kernel = Kernel()\n",
    "kernel_data = kernel.get_kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthesizer allows you to make either a \"2D histogram\" data cube, where particles are sorted into individual pixels, or data cubes where particles are smoothed over their SPH kernels. We'll focus on the latter, but to do the former you simply call `get_data_cube_hist` with an `sed`, `coordinates` and the `Sed` quantity you want to populate the data cube with.\n",
    "\n",
    "To make a smoothed data cube we will must first instantiate the `SpectralCube` and then call `get_data_cube_smoothed` which takes a `sed`, `coordinates`, `smoothing_lengths`, a `kernel`, the threshold of the `kernel` and the `Sed` quantity you want to populate the data cube with. The possible quantities are `\"lnu\"`, `\"luminosity\"` or `\"llam\"` for rest frame luminosities, or `\"fnu\"`, `\"flam\"` or `\"flux\"` for fluxes (the latter 3 require `get_fnu` or `get_fnu0` to have been called). We will make a cube populated with `\"fnu\"`, i.e. the spectral flux density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_start = time.time()\n",
    "\n",
    "# Get the data cube\n",
    "cube = SpectralCube(resolution=resolution, lam=lam, fov=width)\n",
    "\n",
    "# And get the cube itself\n",
    "cube.get_data_cube_smoothed(\n",
    "    sed,\n",
    "    coordinates=gal.stars.coordinates,\n",
    "    smoothing_lengths=gal.stars.smoothing_lengths,\n",
    "    kernel=kernel_data,\n",
    "    kernel_threshold=1,\n",
    "    quantity=\"fnu\",\n",
    ")\n",
    "\n",
    "print(\"Spectral data cube created, took:\", time.time() - cube_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. We now have a spectral data cube to analyse. We can visualise the data cube by making an animation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animate the data cube\n",
    "ani = cube.animate_data_cube(fps=240, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Galaxy helper method\n",
    "\n",
    "If you don't want to use the low level `SpectralCube` object we also include a helper method on a galaxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = gal.get_data_cube(\n",
    "    resolution,\n",
    "    width,\n",
    "    lam,\n",
    "    cube_type=\"hist\",\n",
    "    stellar_spectra=\"intrinsic\",\n",
    "    kernel=kernel,\n",
    "    kernel_threshold=1,\n",
    "    quantity=\"flux\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthesizer-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
