{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947397f6",
   "metadata": {},
   "source": [
    "# Creating Images From Galaxy Particle distributions\n",
    "\n",
    "In this example we show how to create various different types of images and maps from stellar particles. For this purpose we need a stellar distribution and a galaxy. The first section will handle this setup using a CAMELS galaxy, feel free to skip over this section to get to the imaging as the process is well documented elsewhere (e.g. the CAMELS [docs](../cosmo/cosmo_example.ipynb)).\n",
    "\n",
    "## The setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dcb7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from unyt import yr, Myr, kpc, arcsec, nJy, Mpc, Msun, erg, s, Hz\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "from scipy import signal\n",
    "\n",
    "from synthesizer.grid import Grid\n",
    "from synthesizer.filters import FilterCollection as Filters\n",
    "from synthesizer.load_data.load_camels import load_CAMELS_IllustrisTNG\n",
    "from synthesizer.kernel_functions import Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced8bcb",
   "metadata": {},
   "source": [
    "First port of call is initilaising the SPS grid. Here we use the test grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a6043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid\n",
    "grid_name = \"test_grid\"\n",
    "grid_dir = \"../../../tests/test_grid/\"\n",
    "grid = Grid(grid_name, grid_dir=grid_dir, new_lam=np.logspace(2, 5, 600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff77b0a",
   "metadata": {},
   "source": [
    "For demonstration purposes we will just load one of the CAMELS galaxies from the test data. To see how to intialise your own galaxies see [the particle galaxy docs](../galaxies/galaxy_obj.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_start = time.time()\n",
    "\n",
    "# Create galaxy object\n",
    "gal = load_CAMELS_IllustrisTNG(\n",
    "    \"../../../tests/data/\",\n",
    "    snap_name=\"camels_snap.hdf5\",\n",
    "    fof_name=\"camels_subhalo.hdf5\",\n",
    "    physical=True,\n",
    ")[0]\n",
    "\n",
    "print(\"Galaxy created, took:\", time.time() - galaxy_start)\n",
    "\n",
    "print(f\"Galaxy has {gal.stars.nstars} stellar particles\")\n",
    "print(f\"Galaxy gas {gal.gas.nparticles} gas particles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f970eff",
   "metadata": {},
   "source": [
    "### Getting the spectra\n",
    "\n",
    "To make an image we need to map the stellar particle properties onto the SPS grid defined in the `grid` object. To do this we use the galaxy's in built `generate_particle_spectra` method and create `\"total\"` SEDs with both stellar and nebular contributions. This returns an SED object containing lots of helper methods for working with spectra. \n",
    "\n",
    "Here we will use `get_fnu` to convert the rest frame SED into an observed SED which takes into account the previously set redshift stored on the `stars` object. By passing `igm=None` we assume the default `igm` contribution (`Inoue14`). This can be changed to `False` for no IGM or to another IGM model defined in `synthesizer.igm`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_start = time.time()\n",
    "\n",
    "# Calculate the stellar rest frame SEDs for all particles in erg / s / Hz\n",
    "sed = gal.stars.get_particle_spectra_incident(grid)\n",
    "\n",
    "# Calculate the observed SED in nJy\n",
    "sed.get_fnu(cosmo, gal.redshift, igm=None)\n",
    "\n",
    "print(\"Spectra created, took:\", time.time() - spectra_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804df9f6",
   "metadata": {},
   "source": [
    "### Defining filters\n",
    "\n",
    "Next we need to define a set of filters we want photometric images for. This can be done in a number of ways using a `FilterCollection` (see the [filter docs](../filters.ipynb) for a full description). Here we will get Webb filters from the SVO database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_start = time.time()\n",
    "\n",
    "# Define filter list\n",
    "filter_codes = [\n",
    "    \"JWST/NIRCam.F090W\",\n",
    "    \"JWST/NIRCam.F150W\",\n",
    "    \"JWST/NIRCam.F200W\",\n",
    "]\n",
    "\n",
    "# Set up filter object\n",
    "filters = Filters(filter_codes, new_lam=grid.lam)\n",
    "\n",
    "print(\"Filters created, took:\", time.time() - filter_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a428ee3",
   "metadata": {},
   "source": [
    "### Getting photometry\n",
    "\n",
    "Prior to making the image itself we need to get the luminosity in the filters we just defined. To do this we can use the `Sed` method to get photometry from a spectra. Here we are making images of the incident flux so we only need to get the photometry for that spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c109d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "phot_start = time.time()\n",
    "\n",
    "gal.stars.particle_spectra[\"incident\"].get_photo_luminosities(filters)\n",
    "\n",
    "print(\"Photometry computed, took:\", time.time() - phot_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fefc73",
   "metadata": {},
   "source": [
    "## Imaging\n",
    "\n",
    "The last step before we can make any images is to define the resolution of our images and the FOV (or width) of the images. These must have units associated to them to enable the code to internally transform all quantites to a consistent unit system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01abb509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the width of the image\n",
    "width = 30 * kpc\n",
    "\n",
    "# Define image resolution (here we arbitrarily set it to 100 pixels along an axis)\n",
    "resolution = width / 200\n",
    "\n",
    "print(\n",
    "    \"Image width is %.2f kpc with %.2f kpc resolution\"\n",
    "    % (width.value, resolution.value)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e424d79",
   "metadata": {},
   "source": [
    "## Photometric imaging\n",
    "\n",
    "Now we have everything we need to make images. Although it is possible to work with the low level `ImageCollection` and `Image` methods we will here use the interface on a `Galaxy` to do everything. There are two of these helper methods, `get_imgs_luminosity` for luminosity images, and `get_imgs_flux` for flux images. We will focus on the former here.\n",
    "\n",
    "The image helper methods both take the image properties we previously defined and a type of photometry for the image, these types can be any spectra for which you have calculated photometry, e.g. `\"incident\"`, `\"intrinsic\"`, or `\"attenuated\"`, for either stars (`stellar_photometry`) or black holes (`blackhole_photometry`). If both a stellar and black hole photometry type are passed then an image is made for each component before they are combined and returned.\n",
    "\n",
    "Images can either be simple 2D histograms or the particles can be smoothed over their kernels. What type of image is made is controlled by the `img_type` argument. Below we demonstrate both approaches, however, for the latter we also need to define a kernel, which we have already imported from the `kernel_functions` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_start = time.time()\n",
    "\n",
    "# Get the SPH kernel\n",
    "sph_kernel = Kernel()\n",
    "kernel_data = sph_kernel.get_kernel()\n",
    "\n",
    "# Get the image\n",
    "hist_imgs = gal.get_images_luminosity(\n",
    "    resolution,\n",
    "    fov=width,\n",
    "    img_type=\"hist\",\n",
    "    stellar_photometry=\"incident\",\n",
    "    blackhole_photometry=None,\n",
    ")\n",
    "\n",
    "# Get the image\n",
    "smooth_imgs = gal.get_images_luminosity(\n",
    "    resolution,\n",
    "    fov=width,\n",
    "    img_type=\"smoothed\",\n",
    "    stellar_photometry=\"incident\",\n",
    "    blackhole_photometry=None,\n",
    "    kernel=kernel_data,\n",
    "    kernel_threshold=1,\n",
    ")\n",
    "\n",
    "print(\"Images took:\", time.time() - img_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b2ce8c",
   "metadata": {},
   "source": [
    "When making images in multiple bands the image arrays themselves are stored on the returned `ImageCollection` in a dictionary called `imgs` of the form `{filter_code: Image}`, where an `Image` is a container including the image array itself (`arr`), unit information (`units`) and the `resolution` and `fov` of the image. An Image also includes a number of different methods for manipulating and visuallising individual `Image`s. \n",
    "\n",
    "Below we will extract this dictionary and plot each of the images we have made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f5a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets set up a simple normalisation across all images\n",
    "vmax = 0\n",
    "for img in hist_imgs.values():\n",
    "    up = np.percentile(img.arr, 99.9)\n",
    "    if up > vmax:\n",
    "        vmax = up\n",
    "hist_norm = cm.Normalize(vmin=0, vmax=vmax)\n",
    "vmax = 0\n",
    "for img in smooth_imgs.values():\n",
    "    up = np.percentile(img.arr, 99.9)\n",
    "    if up > vmax:\n",
    "        vmax = up\n",
    "smooth_norm = cm.Normalize(vmin=0, vmax=vmax)\n",
    "\n",
    "\n",
    "# Set up plot\n",
    "fig = plt.figure(figsize=(4 * len(filters), 4 * 2))\n",
    "gs = gridspec.GridSpec(2, len(filters), hspace=0.0, wspace=0.0)\n",
    "\n",
    "# Create top row\n",
    "axes = []\n",
    "for i in range(len(filters)):\n",
    "    axes.append(fig.add_subplot(gs[0, i]))\n",
    "\n",
    "# Loop over images plotting them\n",
    "for ax, fcode in zip(axes, filter_codes):\n",
    "    ax.imshow(hist_imgs[fcode].arr, norm=hist_norm, cmap=\"Greys_r\")\n",
    "    ax.set_title(fcode)\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"both\",\n",
    "        left=False,\n",
    "        right=False,\n",
    "        labelleft=False,\n",
    "        labelright=False,\n",
    "        bottom=False,\n",
    "        top=False,\n",
    "        labelbottom=False,\n",
    "        labeltop=False,\n",
    "    )\n",
    "\n",
    "# Set y axis label on left most plot\n",
    "axes[0].set_ylabel(\"Histogram\")\n",
    "\n",
    "# Create bottom row\n",
    "axes = []\n",
    "for i in range(len(filters)):\n",
    "    axes.append(fig.add_subplot(gs[1, i]))\n",
    "\n",
    "# Loop over images plotting them\n",
    "for ax, fcode in zip(axes, filter_codes):\n",
    "    ax.imshow(smooth_imgs[fcode].arr, norm=smooth_norm, cmap=\"Greys_r\")\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"both\",\n",
    "        left=False,\n",
    "        right=False,\n",
    "        labelleft=False,\n",
    "        labelright=False,\n",
    "        bottom=False,\n",
    "        top=False,\n",
    "        labelbottom=False,\n",
    "        labeltop=False,\n",
    "    )\n",
    "\n",
    "# Set y axis label on left most plot\n",
    "axes[0].set_ylabel(\"Smoothed\")\n",
    "\n",
    "# Plot the image\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a548ce",
   "metadata": {},
   "source": [
    "## Applying a Point Spread Function (PSF)\n",
    "\n",
    "Of course, the smoothed distribution is only part of the story. To properly model observations by a particular observatory we need to take into account the smoothing due to the PSF of the telescope. \n",
    "\n",
    "To apply a PSF we can either use `Image.apply_psf` on individual `Image` objects or apply a dictionary of PSFs of the form `{filter_code: psf_array}`, to each image in an `ImageCollection` with the `apply_psfs` method. Here we will just create a fake gaussian PSF for all filters but PSFs can be sourced however the user wishes (for Webb we recommend the _webbpsf_ package) as long as a simple numpy array is passed within the psf dictionary for each filter.\n",
    "\n",
    "To get the most accurate result from the PSF convolution it is recommended to do the convolution on a super sampled image. Although we will here just supersample the images we just made, it is recommended to first make the images at the super sampled resolution and then subsequently downsample after the fact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fake PSF for each filter\n",
    "psf = np.outer(signal.windows.gaussian(100, 3), signal.windows.gaussian(100, 3))\n",
    "psfs = {f: psf for f in filters.filter_codes}\n",
    "\n",
    "img_start = time.time()\n",
    "\n",
    "# Supersample the image\n",
    "smooth_imgs.supersample(2)\n",
    "\n",
    "# Apply the PSFs\n",
    "psf_imgs = smooth_imgs.apply_psfs(psfs)\n",
    "\n",
    "# And downsample back to the native resolution\n",
    "smooth_imgs.downsample(0.5)\n",
    "psf_imgs.downsample(0.5)\n",
    "\n",
    "print(\"PSF images made, took:\", time.time() - img_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb121d1c",
   "metadata": {},
   "source": [
    "`apply_psfs` returns a new `ImageCollection` containing the newly convolved `Image`s. We can now use the plotting helper function to plot these images with some normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847dac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets set up a simple normalisation across all images\n",
    "vmax = 0\n",
    "for img in psf_imgs.values():\n",
    "    up = np.percentile(img.arr, 99.9)\n",
    "    if up > vmax:\n",
    "        vmax = up\n",
    "\n",
    "# Get the plot\n",
    "fig, ax = psf_imgs.plot_images(show=True, vmin=0, vmax=vmax)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583c16ea",
   "metadata": {},
   "source": [
    "## Applying noise\n",
    "\n",
    "The final ingredient for a fully forward modelled synthetic image is a noise field. We include 4 different to approaches to include noise: \n",
    "- `apply_noise_array`: Add an exist noise field/array.\n",
    "- `apply_noise_from_std`: Derive a noise distribution, centered on 0, from a user specified standard deviation, and then generate and add a noise array. \n",
    "- `apply_noise_from_snr` (aperture): Derive a noise distribution from a Signal-to-Noise Ratio (SNR), defined in an aperture with size `aperture_radius` and a specified `depth`. This will derive the standard deviation of the nosie distribution assuming $SNR= S / \\sigma$ for an aperture before deriving the per pixel noise, computing the noise array and adding it.\n",
    "- `apply_noise_from_snr` (point source): Derive a noise distribution from a SNR and depth. This will derive the standard deviation of the noise distribution assuming $SNR= S / \\sigma$ for a pixel before computing the noise array and adding it. This behaviour can be achieved by omitting `aperture_radius` in the call to `apply_noise_from_snr`\n",
    "    \n",
    "As with applying a PSF, these methods have singular versions (as listed above) which can be used on an individual `Image` and pluralised versions on an `ImageCollection` which take dictionaries for each of the arguments. \n",
    "\n",
    "If an image has units then the passed `noise_arr` or `noise_std` must also have units.\n",
    "\n",
    "Applying noise with any of the methods described above will return a new `ImageCollection`/`Image` contain the noisy image. In addition to the noisy image (stored under `Image.arr`) the new `Image` (or the new `Image`s within an `ImageCollection`) will contain the noise array stored in the `noise_arr` attribute and the weight map stored in the `weight_map` attribute on the `Image`.\n",
    "\n",
    "Below we demonstrate each method using the `ImageCollection` interface. We will not explictly show the noise and weight maps but know they are there if you need them (at `Image.noise_arr` and `Image.weight_map`).\n",
    "\n",
    "### Noise arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396666e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_start = time.time()\n",
    "\n",
    "# Get a noise array for each filter\n",
    "noises = {f: np.random.normal(loc=0, scale=10**26., size=(psf_imgs.npix)) * erg / s / Hz for f in psf_imgs.keys()}\n",
    "\n",
    "# Apply the noise array\n",
    "noise_array_imgs = psf_imgs.apply_noise_arrays(noises)\n",
    "\n",
    "print(\"Noisy images made, took:\", time.time() - img_start)\n",
    "\n",
    "# Get the plot\n",
    "fig, ax = noise_array_imgs.plot_images(show=True, vmin=0, vmax=vmax)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d7b47",
   "metadata": {},
   "source": [
    "### Noise from standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a0e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_start = time.time()\n",
    "\n",
    "# Get a noise standard deviation for each filter\n",
    "noise_stds = {f: 10**26.3 * erg / s / Hz for f in psf_imgs.keys()}\n",
    "\n",
    "# Apply the noise array\n",
    "noise_std_imgs = psf_imgs.apply_noise_from_stds(noise_stds)\n",
    "\n",
    "print(\"Noisy images made, took:\", time.time() - img_start)\n",
    "\n",
    "# Get the plot\n",
    "fig, ax = noise_std_imgs.plot_images(show=True, vmin=0, vmax=vmax)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c132319",
   "metadata": {},
   "source": [
    "### Noise from an aperture depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e8d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dictionaries with the noise properties for each filter\n",
    "snrs = {f: 5 for f in psf_imgs.keys()}\n",
    "depths = {f: 10**28. * erg / s / Hz for f in psf_imgs.keys()}\n",
    "\n",
    "# Apply the noise array\n",
    "noise_app_imgs = psf_imgs.apply_noise_from_snrs(snrs=snrs, depths=depths, aperture_radius=0.5 * kpc)\n",
    "\n",
    "print(\"Noisy images made, took:\", time.time() - img_start)\n",
    "\n",
    "# Get the plot\n",
    "fig, ax = noise_app_imgs.plot_images(show=True, vmin=0, vmax=vmax)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a9f27e",
   "metadata": {},
   "source": [
    "### Noise from point source depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e9a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dictionaries with the noise properties for each filter\n",
    "snrs = {f: 5 for f in psf_imgs.keys()}\n",
    "depths = {f: 10**27. * erg / s / Hz for f in psf_imgs.keys()}\n",
    "\n",
    "# Apply the noise array\n",
    "noise_ps_imgs = psf_imgs.apply_noise_from_snrs(snrs=snrs, depths=depths)\n",
    "\n",
    "print(\"Noisy images made, took:\", time.time() - img_start)\n",
    "\n",
    "# Get the plot\n",
    "fig, ax = noise_ps_imgs.plot_images(show=True, vmin=0, vmax=vmax)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5598bc9a",
   "metadata": {},
   "source": [
    "## Making an RGB image\n",
    "\n",
    "Finally we can use the RGB image method on the `ImageCollection` to make quick RGB images by simply providing a dictionary detailing which filters we want in which bands and optional weights for each filter which we will ignore here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f560d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the rgb image from the psf image above example using our 3 filters\n",
    "rgb_img = noise_ps_imgs.make_rgb_image(\n",
    "    rgb_filters={\n",
    "        \"R\": [\n",
    "            \"JWST/NIRCam.F200W\",\n",
    "        ],\n",
    "        \"G\": [\n",
    "            \"JWST/NIRCam.F150W\",\n",
    "        ],\n",
    "        \"B\": [\n",
    "            \"JWST/NIRCam.F090W\",\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "\n",
    "# Set up minima and maxima\n",
    "vmin = -np.percentile(rgb_img, 32)\n",
    "vmax = np.percentile(rgb_img, 99.9)\n",
    "norm = cm.Normalize(vmin=vmin, vmax=vmax, clip=True)\n",
    "print(\"Scaling to:\", vmin, \"->\", vmax)\n",
    "\n",
    "# Normalise the image.\n",
    "rgb_img = norm(rgb_img)\n",
    "\n",
    "print(rgb_img.shape)\n",
    "\n",
    "# Plot the image\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(rgb_img, origin=\"lower\", interpolation=\"nearest\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
