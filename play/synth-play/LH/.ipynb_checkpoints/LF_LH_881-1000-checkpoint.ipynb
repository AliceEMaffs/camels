{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Absolute magnitude is defined to be the apparent magnitude an object would have if it were located at a distance of 10 parsecs.\n",
    "In astronomy, absolute magnitude (M) is a measure of the luminosity of a celestial object on an inverse logarithmic astronomical magnitude scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3411/854112820.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/jovyan/camels/play/synth-play/LH\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import hdf5plugin\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from unyt import yr, Myr, kpc, arcsec, nJy, Mpc, Msun, erg, s, Hz\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "from scipy import signal\n",
    "import os \n",
    "import csv\n",
    "import resource\n",
    "\n",
    "\n",
    "from synthesizer.grid import Grid\n",
    "from synthesizer.parametric import SFH, ZDist\n",
    "from synthesizer.particle.stars import sample_sfhz\n",
    "from synthesizer.parametric import Stars as ParametricStars\n",
    "from synthesizer.particle.particles import CoordinateGenerator\n",
    "from synthesizer.filters import Filter, FilterCollection\n",
    "from synthesizer.sed import combine_list_of_seds\n",
    "\n",
    "from synthesizer.load_data.load_camels import load_CAMELS_IllustrisTNG\n",
    "from synthesizer.kernel_functions import Kernel\n",
    "\n",
    "from synthesizer.conversions import lnu_to_absolute_mag\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current directory:\", current_directory)\n",
    "# Start the timer\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Alternative method for LF:\n",
    "# try this method again, but using AB mag instead of mass, and suply your own bins (up to -17, say)\n",
    "def calc_lf(ab_mag, volume, massBinLimits):\n",
    "# OG:        hist, dummy = np.histogram(np.log10(mstar), bins = massBinLimits)\n",
    "        hist, dummy = np.histogram(ab_mag, bins = massBinLimits)\n",
    "        hist = np.float64(hist)\n",
    "        phi = (hist / volume) / (massBinLimits[1] - massBinLimits[0])\n",
    "        phi_sigma = (np.sqrt(hist) / volume) /\\\n",
    "                    (massBinLimits[1] - massBinLimits[0]) # Poisson errors\n",
    "        return phi, phi_sigma, hist\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "phi_arr =[] #phi\n",
    "phi_sigma_arr =[] # phi_sigma\n",
    "hist_arr = [] # hist\n",
    "z_arr = [] #redshift_074, \n",
    "abs_mag_arr = [] #absolute mag (th filter)\n",
    "Vcom_arr = [] # comoving vol\n",
    "massBinLimits_arr = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(phi_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LH_881',\n",
       " 'LH_882',\n",
       " 'LH_883',\n",
       " 'LH_884',\n",
       " 'LH_885',\n",
       " 'LH_886',\n",
       " 'LH_887',\n",
       " 'LH_888',\n",
       " 'LH_889',\n",
       " 'LH_890',\n",
       " 'LH_891',\n",
       " 'LH_892',\n",
       " 'LH_893',\n",
       " 'LH_894',\n",
       " 'LH_895',\n",
       " 'LH_896',\n",
       " 'LH_897',\n",
       " 'LH_898',\n",
       " 'LH_899',\n",
       " 'LH_900',\n",
       " 'LH_901',\n",
       " 'LH_902',\n",
       " 'LH_903',\n",
       " 'LH_904',\n",
       " 'LH_905',\n",
       " 'LH_906',\n",
       " 'LH_907',\n",
       " 'LH_908',\n",
       " 'LH_909',\n",
       " 'LH_910',\n",
       " 'LH_911',\n",
       " 'LH_912',\n",
       " 'LH_913',\n",
       " 'LH_914',\n",
       " 'LH_915',\n",
       " 'LH_916',\n",
       " 'LH_917',\n",
       " 'LH_918',\n",
       " 'LH_919',\n",
       " 'LH_920',\n",
       " 'LH_921',\n",
       " 'LH_922',\n",
       " 'LH_923',\n",
       " 'LH_924',\n",
       " 'LH_925',\n",
       " 'LH_926',\n",
       " 'LH_927',\n",
       " 'LH_928',\n",
       " 'LH_929',\n",
       " 'LH_930',\n",
       " 'LH_931',\n",
       " 'LH_932',\n",
       " 'LH_933',\n",
       " 'LH_934',\n",
       " 'LH_935',\n",
       " 'LH_936',\n",
       " 'LH_937',\n",
       " 'LH_938',\n",
       " 'LH_939',\n",
       " 'LH_940',\n",
       " 'LH_941',\n",
       " 'LH_942',\n",
       " 'LH_943',\n",
       " 'LH_944',\n",
       " 'LH_945',\n",
       " 'LH_946',\n",
       " 'LH_947',\n",
       " 'LH_948',\n",
       " 'LH_949',\n",
       " 'LH_950',\n",
       " 'LH_951',\n",
       " 'LH_952',\n",
       " 'LH_953',\n",
       " 'LH_954',\n",
       " 'LH_955',\n",
       " 'LH_956',\n",
       " 'LH_957',\n",
       " 'LH_958',\n",
       " 'LH_959',\n",
       " 'LH_960',\n",
       " 'LH_961',\n",
       " 'LH_962',\n",
       " 'LH_963',\n",
       " 'LH_964',\n",
       " 'LH_965',\n",
       " 'LH_966',\n",
       " 'LH_967',\n",
       " 'LH_968',\n",
       " 'LH_969',\n",
       " 'LH_970',\n",
       " 'LH_971',\n",
       " 'LH_972',\n",
       " 'LH_973',\n",
       " 'LH_974',\n",
       " 'LH_975',\n",
       " 'LH_976',\n",
       " 'LH_977',\n",
       " 'LH_978',\n",
       " 'LH_979',\n",
       " 'LH_980',\n",
       " 'LH_981',\n",
       " 'LH_982',\n",
       " 'LH_983',\n",
       " 'LH_984',\n",
       " 'LH_985',\n",
       " 'LH_986',\n",
       " 'LH_987',\n",
       " 'LH_988',\n",
       " 'LH_989',\n",
       " 'LH_990',\n",
       " 'LH_991',\n",
       " 'LH_992',\n",
       " 'LH_993',\n",
       " 'LH_994',\n",
       " 'LH_995',\n",
       " 'LH_996',\n",
       " 'LH_997',\n",
       " 'LH_998',\n",
       " 'LH_999']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#directories = [f'LH_{i}' for i in range(1000)]\n",
    "# TEST:\n",
    "directories = [f'LH_{i}' for i in range(881, 1000)]\n",
    "directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/unyt/array.py:1813: RuntimeWarning: divide by zero encountered in log10\n",
      "  out_arr = func(np.asarray(inp), out=out_func, **kwargs)\n",
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/unyt/array.py:1938: RuntimeWarning: invalid value encountered in divide\n",
      "  out_arr = func(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage during loop:  1462640 bytes\n",
      "Memory usage during loop:  1794276 bytes\n"
     ]
    }
   ],
   "source": [
    "# Try data frame instead\n",
    "grid_name = \"bc03-2016-Miles_chabrier-0.1,100.hdf5\"\n",
    "grid_dir = \"/home/jovyan/\"\n",
    "grid = Grid(grid_name, grid_dir=grid_dir, read_lines=False)\n",
    "    \n",
    "# Create an empty dictionary to store your data\n",
    "data_dict = {}\n",
    "\n",
    "for LH_X in directories:\n",
    "\n",
    "    # get grid for all galaxies\n",
    "    # gives grid of metalicity and age which is used to map on our camels galaxies\n",
    "\n",
    "    # get gals\n",
    "    dir_ = '/home/jovyan/Data/Sims/IllustrisTNG/LH/' + LH_X\n",
    "    gals_074 = load_CAMELS_IllustrisTNG(\n",
    "        dir_,\n",
    "        snap_name='snapshot_074.hdf5', \n",
    "        fof_name='groups_074.hdf5',\n",
    "    )\n",
    "\n",
    "    cat_074 = dir_+'/groups_074.hdf5'\n",
    "    # open file\n",
    "    f = h5py.File(cat_074, 'r')\n",
    "\n",
    "    # read different attributes of the header\n",
    "    boxSize_074 = f['Header'].attrs[u'BoxSize']/1e3 #Mpc/h\n",
    "    redshift_074 = f['Header'].attrs[u'Redshift']\n",
    "\n",
    "\n",
    "    # Filter galaxies to only include those with 100 or more star particles\n",
    "    ## NEED TO ADD FILTER TO GET RID OF ANY GALAXIES WITH LESS THAN 100 star Particles!! This is the resolution limit!!\n",
    "    # Chris: when you load your galaxies in could you do a filter for those with at least 100 star particles? that's the resolution limit\n",
    "    gals_074 = [gal for gal in gals_074 if len(gal.stars.ages) >= 100]\n",
    "    spec_list = []\n",
    "    # Lets work with z=0 so gals_025\n",
    "    for i in gals_074:\n",
    "        gal = i\n",
    "        # get_spectra_incident An Sed object containing the stellar spectra\n",
    "        spec = gal.stars.get_spectra_incident(grid)\n",
    "        spec.get_fnu0()\n",
    "        spec_list.append(spec)\n",
    "\n",
    "    # combine\n",
    "    seds = combine_list_of_seds(spec_list)\n",
    "    filt1 = Filter(\"top_hat/filter.1\", lam_min=1400, lam_max=1600, new_lam=grid.lam)\n",
    "    filt_lst = [filt1]\n",
    "    seds.lnu # rest frame lumd\n",
    "    seds.get_photo_luminosities(filt_lst)\n",
    "    seds.photo_luminosities.photo_luminosities\n",
    "    abs_mag = lnu_to_absolute_mag(seds.photo_luminosities.photo_luminosities)\n",
    "    abs_mag_th = abs_mag[0]\n",
    "    # next steps, get luminosity function for these magnitudes\n",
    "    # co-moving volume: BoxSize_025 and redshift:\n",
    "    little_h =  0.6711\n",
    "    Vphys = (boxSize_074/little_h )**3\n",
    "    Vcom = Vphys * ((1+redshift_074)**3)\n",
    "\n",
    "    massBinLimits = np.arange(-22, -16, 0.5)\n",
    "    phi, phi_sigma, hist = calc_lf(abs_mag_th, Vcom, massBinLimits)\n",
    "    # NOTE: 074 is the same redshift as CV_0/025\n",
    "    massBinLimits = massBinLimits[:-1]\n",
    "\n",
    "    # Store the calculated values in the dictionary with LH_X as the key\n",
    "    data_dict[LH_X] = {\n",
    "        'phi': phi,\n",
    "        'phi_sigma': phi_sigma,\n",
    "        'hist': hist,\n",
    "        'massBinLimits': massBinLimits\n",
    "    }\n",
    "\n",
    "    # Get memory usage in bytes\n",
    "    memory_usage = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "    print(\"Memory usage during loop: \", memory_usage/1000000, \"GB\")\n",
    "\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the dictionary containing all data\n",
    "with open('/home/jovyan/output_test/LH_881-1000.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# will do latest LH_ set in loop as a test\n",
    "label_z = 'z = 0.46'\n",
    "\n",
    "\n",
    "# Plot the luminosity function\n",
    "plt.errorbar(massBinLimits, phi, yerr=phi_sigma, fmt='o', color='blue',label=label_z)\n",
    "plt.xlabel('Absolute Magnitude (AB)')\n",
    "plt.ylabel('Number Density (Mpc^-3 mag^-1)')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.title('Luminosity Function XMM-OM filter')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 103.06453847885132 seconds\n"
     ]
    }
   ],
   "source": [
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage end: 1.794276 bytes\n"
     ]
    }
   ],
   "source": [
    "# Get memory usage in bytes\n",
    "memory_usage = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "print(\"Memory usage end:\", memory_usage/1000000, \"GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
