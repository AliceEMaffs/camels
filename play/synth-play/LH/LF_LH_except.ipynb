{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Absolute magnitude is defined to be the apparent magnitude an object would have if it were located at a distance of 10 parsecs.\n",
    "In astronomy, absolute magnitude (M) is a measure of the luminosity of a celestial object on an inverse logarithmic astronomical magnitude scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6426/2918952320.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/jovyan/camels/play/synth-play/LH\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import hdf5plugin\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from unyt import yr, Myr, kpc, arcsec, nJy, Mpc, Msun, erg, s, Hz\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "from scipy import signal\n",
    "import os \n",
    "import csv\n",
    "import resource\n",
    "import pickle\n",
    "import shutil\n",
    "import json\n",
    "from synthesizer.grid import Grid\n",
    "from synthesizer.parametric import SFH, ZDist\n",
    "from synthesizer.particle.stars import sample_sfhz\n",
    "from synthesizer.parametric import Stars as ParametricStars\n",
    "from synthesizer.particle.particles import CoordinateGenerator\n",
    "from synthesizer.filters import Filter, FilterCollection\n",
    "from synthesizer.sed import combine_list_of_seds\n",
    "\n",
    "from synthesizer.load_data.load_camels import load_CAMELS_IllustrisTNG\n",
    "from synthesizer.kernel_functions import Kernel\n",
    "\n",
    "from synthesizer.conversions import lnu_to_absolute_mag\n",
    "\n",
    "# to clear output\n",
    "from IPython.display import clear_output\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current directory:\", current_directory)\n",
    "# Start the timer\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Alternative method for LF:\n",
    "# try this method again, but using AB mag instead of mass, and suply your own bins (up to -17, say)\n",
    "def calc_lf(ab_mag, volume, massBinLimits):\n",
    "# OG:        hist, dummy = np.histogram(np.log10(mstar), bins = massBinLimits)\n",
    "        hist, dummy = np.histogram(ab_mag, bins = massBinLimits)\n",
    "        hist = np.float64(hist)\n",
    "        phi = (hist / volume) / (massBinLimits[1] - massBinLimits[0])\n",
    "        phi_sigma = (np.sqrt(hist) / volume) /\\\n",
    "                    (massBinLimits[1] - massBinLimits[0]) # Poisson errors\n",
    "        return phi, phi_sigma, hist\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "phi_arr =[] #phi\n",
    "phi_sigma_arr =[] # phi_sigma\n",
    "hist_arr = [] # hist\n",
    "z_arr = [] #redshift_074, \n",
    "abs_mag_arr = [] #absolute mag (th filter)\n",
    "Vcom_arr = [] # comoving vol\n",
    "massBinLimits_arr = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(phi_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LH_200',\n",
       " 'LH_201',\n",
       " 'LH_202',\n",
       " 'LH_203',\n",
       " 'LH_204',\n",
       " 'LH_205',\n",
       " 'LH_206',\n",
       " 'LH_207',\n",
       " 'LH_208',\n",
       " 'LH_209',\n",
       " 'LH_210',\n",
       " 'LH_211',\n",
       " 'LH_212',\n",
       " 'LH_213',\n",
       " 'LH_214',\n",
       " 'LH_215',\n",
       " 'LH_216',\n",
       " 'LH_217',\n",
       " 'LH_218',\n",
       " 'LH_219',\n",
       " 'LH_220',\n",
       " 'LH_221',\n",
       " 'LH_222',\n",
       " 'LH_223',\n",
       " 'LH_224',\n",
       " 'LH_225',\n",
       " 'LH_226',\n",
       " 'LH_227',\n",
       " 'LH_228',\n",
       " 'LH_229',\n",
       " 'LH_230',\n",
       " 'LH_231',\n",
       " 'LH_232',\n",
       " 'LH_233',\n",
       " 'LH_234',\n",
       " 'LH_235',\n",
       " 'LH_236',\n",
       " 'LH_237',\n",
       " 'LH_238',\n",
       " 'LH_239',\n",
       " 'LH_240',\n",
       " 'LH_241',\n",
       " 'LH_242',\n",
       " 'LH_243',\n",
       " 'LH_244',\n",
       " 'LH_245',\n",
       " 'LH_246',\n",
       " 'LH_247',\n",
       " 'LH_248',\n",
       " 'LH_249',\n",
       " 'LH_250',\n",
       " 'LH_251',\n",
       " 'LH_252',\n",
       " 'LH_253',\n",
       " 'LH_254',\n",
       " 'LH_255',\n",
       " 'LH_256',\n",
       " 'LH_257',\n",
       " 'LH_258',\n",
       " 'LH_259',\n",
       " 'LH_260',\n",
       " 'LH_261',\n",
       " 'LH_262',\n",
       " 'LH_263',\n",
       " 'LH_264',\n",
       " 'LH_265',\n",
       " 'LH_266',\n",
       " 'LH_267',\n",
       " 'LH_268',\n",
       " 'LH_269',\n",
       " 'LH_270',\n",
       " 'LH_271',\n",
       " 'LH_272',\n",
       " 'LH_273',\n",
       " 'LH_274',\n",
       " 'LH_275',\n",
       " 'LH_276',\n",
       " 'LH_277',\n",
       " 'LH_278',\n",
       " 'LH_279',\n",
       " 'LH_280',\n",
       " 'LH_281',\n",
       " 'LH_282',\n",
       " 'LH_283',\n",
       " 'LH_284',\n",
       " 'LH_285',\n",
       " 'LH_286',\n",
       " 'LH_287',\n",
       " 'LH_288',\n",
       " 'LH_289',\n",
       " 'LH_290',\n",
       " 'LH_291',\n",
       " 'LH_292',\n",
       " 'LH_293',\n",
       " 'LH_294',\n",
       " 'LH_295',\n",
       " 'LH_296',\n",
       " 'LH_297',\n",
       " 'LH_298',\n",
       " 'LH_299']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#directories = [f'LH_{i}' for i in range(1000)]\n",
    "# TEST:\n",
    "# LH_50 ,LH_104 skipped. bad data, run again later.\n",
    "directories = [f'LH_{i}' for i in range(200, 300)]\n",
    "directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the log file\n",
    "log_file_path = \"/home/jovyan/camels/play/synth-play/LH/log.txt\"\n",
    "\n",
    "# Initialize the list of skipped directories\n",
    "skipped_directories = []\n",
    "\n",
    "# Function to log messages\n",
    "def log_message(message):\n",
    "    with open(log_file_path, 'a') as log_file:\n",
    "        log_file.write(message + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221, 7, 401)\n"
     ]
    }
   ],
   "source": [
    "grid_name = \"bc03-2016-Miles_chabrier-0.1,100.hdf5\"\n",
    "grid_dir = \"/home/jovyan/\"\n",
    "\n",
    "# Create a new grid\n",
    "#grid = Grid(grid_name, grid_dir=grid_dir, read_lines=False)\n",
    "\n",
    "# instead of using a filter, which requires us to load in large SEDs first, pass the grid wavelength\n",
    "#filt1 = Filter(\"top_hat/filter.1\", lam_min=1400, lam_max=1600, new_lam=grid.lam)\n",
    "#filt_lst = [filt1]\n",
    "\n",
    "# Define a new set of wavelengths\n",
    "lims_lams=(1400, 1600)\n",
    "\n",
    "grid = Grid(grid_name, grid_dir=grid_dir, lam_lims=lims_lams, read_lines=False)\n",
    "print(grid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the directory where the text files will be saved\n",
    "output_dir = \"/home/jovyan/camels/play/synth-play/LH/output/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2J"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m dir_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/jovyan/Data/Sims/IllustrisTNG/LH/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m LH_X\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     gals_074 \u001b[38;5;241m=\u001b[39m \u001b[43mload_CAMELS_IllustrisTNG\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdir_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43msnap_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msnapshot_074.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfof_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgroups_074.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Suppress output\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     17\u001b[0m     log_message(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading CAMELS data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLH_X\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/synthesizer/load_data/load_camels.py:228\u001b[0m, in \u001b[0;36mload_CAMELS_IllustrisTNG\u001b[0;34m(_dir, snap_name, fof_name, fof_dir, verbose, dtm, physical)\u001b[0m\n\u001b[1;32m    225\u001b[0m _ages \u001b[38;5;241m=\u001b[39m cosmo\u001b[38;5;241m.\u001b[39mage(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m form_time \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    226\u001b[0m ages \u001b[38;5;241m=\u001b[39m (universe_age \u001b[38;5;241m-\u001b[39m _ages)\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e9\u001b[39m  \u001b[38;5;66;03m# yr\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_CAMELS\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetallicities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetallicity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms_oxygen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms_oxygen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms_hydrogen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms_hydrogen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms_hsml\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhsml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoods\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mg_coods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg_coods\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mg_masses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg_masses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mg_metallicities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg_metals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mg_hsml\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg_hsml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstar_forming\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstar_forming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mredshift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredshift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcentre\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/synthesizer/load_data/load_camels.py:96\u001b[0m, in \u001b[0;36m_load_CAMELS\u001b[0;34m(lens, imasses, ages, metallicities, s_oxygen, s_hydrogen, coods, masses, g_coods, g_masses, g_metallicities, g_hsml, star_forming, redshift, centre, s_hsml, dtm)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m         smoothing_lengths \u001b[38;5;241m=\u001b[39m s_hsml[b:e] \u001b[38;5;241m*\u001b[39m kpc\n\u001b[1;32m     90\u001b[0m     galaxies[i]\u001b[38;5;241m.\u001b[39mload_stars(\n\u001b[1;32m     91\u001b[0m         initial_masses\u001b[38;5;241m=\u001b[39mimasses[b:e] \u001b[38;5;241m*\u001b[39m Msun,\n\u001b[1;32m     92\u001b[0m         ages\u001b[38;5;241m=\u001b[39mages[b:e] \u001b[38;5;241m*\u001b[39m yr,\n\u001b[1;32m     93\u001b[0m         metallicities\u001b[38;5;241m=\u001b[39mmetallicities[b:e],\n\u001b[1;32m     94\u001b[0m         s_oxygen\u001b[38;5;241m=\u001b[39ms_oxygen[b:e],\n\u001b[1;32m     95\u001b[0m         s_hydrogen\u001b[38;5;241m=\u001b[39ms_hydrogen[b:e],\n\u001b[0;32m---> 96\u001b[0m         coordinates\u001b[38;5;241m=\u001b[39m\u001b[43mcoods\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m:\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkpc\u001b[49m,\n\u001b[1;32m     97\u001b[0m         current_masses\u001b[38;5;241m=\u001b[39mmasses[b:e] \u001b[38;5;241m*\u001b[39m Msun,\n\u001b[1;32m     98\u001b[0m         smoothing_lengths\u001b[38;5;241m=\u001b[39msmoothing_lengths,\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m begin, end \u001b[38;5;241m=\u001b[39m get_len(lens[:, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (b, e) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(begin, end)):\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/unyt/unit_object.py:375\u001b[0m, in \u001b[0;36mUnit.__rmul__\u001b[0;34m(self, u)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rmul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, u):\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__mul__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/unyt/unit_object.py:397\u001b[0m, in \u001b[0;36mUnit.__mul__\u001b[0;34m(self, u)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m ():\n\u001b[1;32m    396\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _import_cache_singleton\u001b[38;5;241m.\u001b[39muq(data, units, bypass_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_import_cache_singleton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mua\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbypass_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensions \u001b[38;5;129;01mis\u001b[39;00m logarithmic \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m u\u001b[38;5;241m.\u001b[39mis_dimensionless:\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUnitOperation(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to multiply \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/unyt/array.py:586\u001b[0m, in \u001b[0;36munyt_array.__new__\u001b[0;34m(cls, input_array, units, registry, dtype, bypass_validation, name)\u001b[0m\n\u001b[1;32m    584\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m input_array\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    585\u001b[0m obj \u001b[38;5;241m=\u001b[39m input_array\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m--> 586\u001b[0m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munits\u001b[49m \u001b[38;5;241m=\u001b[39m input_units\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m registry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m     obj\u001b[38;5;241m.\u001b[39munits\u001b[38;5;241m.\u001b[39mregistry \u001b[38;5;241m=\u001b[39m registry\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop over multiple LH directories\n",
    "for LH_X in directories:\n",
    "    try:\n",
    "        log_message(f\"Processing directory: {LH_X}\")\n",
    "\n",
    "        # Get gals\n",
    "        dir_ = '/home/jovyan/Data/Sims/IllustrisTNG/LH/' + LH_X\n",
    "\n",
    "        try:\n",
    "            gals_074 = load_CAMELS_IllustrisTNG(\n",
    "                dir_,\n",
    "                snap_name='snapshot_074.hdf5', \n",
    "                fof_name='groups_074.hdf5',\n",
    "                verbose=False  # Suppress output\n",
    "            )\n",
    "        except Exception as e:\n",
    "            log_message(f\"Error loading CAMELS data for {LH_X}: {e}\")\n",
    "            skipped_directories.append(LH_X)\n",
    "            continue\n",
    "\n",
    "        # Clear the output after each iteration\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        try:\n",
    "            cat_074 = dir_+'/groups_074.hdf5'\n",
    "            # Open file\n",
    "            f_h5py = h5py.File(cat_074, 'r')\n",
    "\n",
    "            # Read different attributes of the header\n",
    "            boxSize_074 = f_h5py['Header'].attrs[u'BoxSize']/1e3 # Mpc/h\n",
    "            redshift_074 = f_h5py['Header'].attrs[u'Redshift']\n",
    "        except Exception as e:\n",
    "            log_message(f\"Error reading HDF5 file for {LH_X}: {e}\")\n",
    "            skipped_directories.append(LH_X)\n",
    "            continue\n",
    "\n",
    "        # Filter galaxies to only include those with 100 or more star particles\n",
    "        try:\n",
    "            gals_074 = [gal for gal in gals_074 if len(gal.stars.ages) >= 100]\n",
    "            spec_list = []\n",
    "            # Lets work with z=0 so gals_025\n",
    "            for i in gals_074:\n",
    "                gal = i\n",
    "                # Get spectra incident An Sed object containing the stellar spectra\n",
    "                spec = gal.stars.get_spectra_incident(grid)\n",
    "                spec.get_fnu0()\n",
    "                spec_list.append(spec)\n",
    "\n",
    "            # Combine\n",
    "            seds = combine_list_of_seds(spec_list)\n",
    "            filt1 = Filter(\"top_hat/filter.1\", lam_min=1400, lam_max=1600, new_lam=grid.lam)\n",
    "            filt_lst = [filt1]\n",
    "            seds.lnu # Rest frame lumd\n",
    "            seds.get_photo_luminosities(filt_lst)\n",
    "            seds.photo_luminosities.photo_luminosities\n",
    "            abs_mag = lnu_to_absolute_mag(seds.photo_luminosities.photo_luminosities)\n",
    "            abs_mag_th = abs_mag[0]\n",
    "            # Next steps, get luminosity function for these magnitudes\n",
    "            # Co-moving volume: BoxSize_025 and redshift:\n",
    "            little_h =  0.6711\n",
    "            Vphys = (boxSize_074/little_h )**3\n",
    "            Vcom = Vphys * ((1+redshift_074)**3)\n",
    "\n",
    "            massBinLimits = np.arange(-22, -16, 0.5)\n",
    "            phi, phi_sigma, hist = calc_lf(abs_mag_th, Vcom, massBinLimits)\n",
    "            # NOTE: 074 is the same redshift as CV_0/025\n",
    "            massBinLimits = massBinLimits[:-1]\n",
    "        except Exception as e:\n",
    "            log_message(f\"Error processing galaxy data for {LH_X}: {e}\")\n",
    "            skipped_directories.append(LH_X)\n",
    "            continue\n",
    "\n",
    "        # Define output file path\n",
    "        output_file = f\"{output_dir}{LH_X}.txt\"\n",
    "\n",
    "        try:\n",
    "            # Write the data to the text file line by line\n",
    "            with open(output_file, 'w') as txtfile:\n",
    "                # Write phi values\n",
    "                txtfile.write(\"phi\\n\")\n",
    "                for value in phi:\n",
    "                    txtfile.write(f\"{value}\\n\")\n",
    "\n",
    "                # Write phi_sigma values\n",
    "                txtfile.write(\"phi_sigma\\n\")\n",
    "                for value in phi_sigma:\n",
    "                    txtfile.write(f\"{value}\\n\")\n",
    "\n",
    "                # Write hist values\n",
    "                txtfile.write(\"hist\\n\")\n",
    "                for value in hist:\n",
    "                    txtfile.write(f\"{value}\\n\")\n",
    "\n",
    "                # Write massBinLimits values\n",
    "                txtfile.write(\"massBinLimits\\n\")\n",
    "                for value in massBinLimits:\n",
    "                    txtfile.write(f\"{value}\\n\")\n",
    "            \n",
    "            log_message(f\"Written out: {output_file}\")\n",
    "        except Exception as e:\n",
    "            log_message(f\"Error writing output file for {LH_X}: {e}\")\n",
    "            skipped_directories.append(LH_X)\n",
    "            continue\n",
    "\n",
    "        # Clear the terminal output after each iteration\n",
    "        os.system('cls' if os.name == 'nt' else 'clear')       \n",
    "\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error processing {LH_X}: {e}\")\n",
    "        skipped_directories.append(LH_X)\n",
    "\n",
    "# Write the skipped directories to the log file at the end\n",
    "if skipped_directories:\n",
    "    log_message(\"Skipped directories:\")\n",
    "    for dir in skipped_directories:\n",
    "        log_message(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try data frame instead\n",
    "grid_name = \"bc03-2016-Miles_chabrier-0.1,100.hdf5\"\n",
    "grid_dir = \"/home/jovyan/\"\n",
    "grid = Grid(grid_name, grid_dir=grid_dir, read_lines=False)\n",
    "\n",
    "# Define the directory where the text files will be saved\n",
    "output_dir = \"/home/jovyan/camels/play/synth-play/LH/output/\"\n",
    "\n",
    "for LH_X in directories:\n",
    "    try:\n",
    "        # get grid for all galaxies\n",
    "        # gives grid of metalicity and age which is used to map on our camels galaxies\n",
    "\n",
    "        # get gals\n",
    "        dir_ = '/home/jovyan/Data/Sims/IllustrisTNG/LH/' + LH_X\n",
    "        gals_074 = load_CAMELS_IllustrisTNG(\n",
    "            dir_,\n",
    "            snap_name='snapshot_074.hdf5', \n",
    "            fof_name='groups_074.hdf5',\n",
    "            verbose=False  # Suppress output\n",
    "        )\n",
    "        # Clear the output after each iteration\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        cat_074 = dir_+'/groups_074.hdf5'\n",
    "        # open file\n",
    "        f_h5py = h5py.File(cat_074, 'r')\n",
    "\n",
    "        # read different attributes of the header\n",
    "        boxSize_074 = f_h5py['Header'].attrs[u'BoxSize']/1e3 #Mpc/h\n",
    "        redshift_074 = f_h5py['Header'].attrs[u'Redshift']\n",
    "\n",
    "        # Filter galaxies to only include those with 100 or more star particles\n",
    "        gals_074 = [gal for gal in gals_074 if len(gal.stars.ages) >= 100]\n",
    "        spec_list = []\n",
    "        # Lets work with z=0 so gals_025\n",
    "        for i in gals_074:\n",
    "            gal = i\n",
    "            # get_spectra_incident An Sed object containing the stellar spectra\n",
    "            spec = gal.stars.get_spectra_incident(grid)\n",
    "            spec.get_fnu0()\n",
    "            spec_list.append(spec)\n",
    "\n",
    "        # combine\n",
    "        seds = combine_list_of_seds(spec_list)\n",
    "        filt1 = Filter(\"top_hat/filter.1\", lam_min=1400, lam_max=1600, new_lam=grid.lam)\n",
    "        filt_lst = [filt1]\n",
    "        seds.lnu # rest frame lumd\n",
    "        seds.get_photo_luminosities(filt_lst)\n",
    "        seds.photo_luminosities.photo_luminosities\n",
    "        abs_mag = lnu_to_absolute_mag(seds.photo_luminosities.photo_luminosities)\n",
    "        abs_mag_th = abs_mag[0]\n",
    "        # next steps, get luminosity function for these magnitudes\n",
    "        # co-moving volume: BoxSize_025 and redshift:\n",
    "        little_h =  0.6711\n",
    "        Vphys = (boxSize_074/little_h )**3\n",
    "        Vcom = Vphys * ((1+redshift_074)**3)\n",
    "\n",
    "        massBinLimits = np.arange(-22, -16, 0.5)\n",
    "        phi, phi_sigma, hist = calc_lf(abs_mag_th, Vcom, massBinLimits)\n",
    "        # NOTE: 074 is the same redshift as CV_0/025\n",
    "        massBinLimits = massBinLimits[:-1]\n",
    "\n",
    "        # Define output file path\n",
    "        output_file = f\"{output_dir}{LH_X}.txt\"\n",
    "\n",
    "        # Write the data to the text file line by line\n",
    "        with open(output_file, 'w') as txtfile:\n",
    "            # Write phi values\n",
    "            txtfile.write(\"phi\\n\")\n",
    "            for value in phi:\n",
    "                txtfile.write(f\"{value}\\n\")\n",
    "\n",
    "            # Write phi_sigma values\n",
    "            txtfile.write(\"phi_sigma\\n\")\n",
    "            for value in phi_sigma:\n",
    "                txtfile.write(f\"{value}\\n\")\n",
    "\n",
    "            # Write hist values\n",
    "            txtfile.write(\"hist\\n\")\n",
    "            for value in hist:\n",
    "                txtfile.write(f\"{value}\\n\")\n",
    "\n",
    "            # Write massBinLimits values\n",
    "            txtfile.write(\"massBinLimits\\n\")\n",
    "            for value in massBinLimits:\n",
    "                txtfile.write(f\"{value}\\n\")\n",
    "\n",
    "        print('Written out: /home/jovyan/camels/play/synth-play/LH/output/',LH_X)\n",
    "\n",
    "        # Clear the terminal output after each iteration\n",
    "        os.system('cls' if os.name == 'nt' else 'clear')       \n",
    "        \n",
    "    except Exception as e:\n",
    "        error_message = f\"Error processing {LH_X}: {e}\"\n",
    "        print(error_message)\n",
    "        skipped_directories.append(LH_X)\n",
    "\n",
    "        # Append the error message to the log file\n",
    "        with open(log_file_path, 'a') as log_file:\n",
    "            log_file.write(error_message + '\\n')\n",
    "\n",
    "# Write the skipped directories to the log file at the end\n",
    "if skipped_directories:\n",
    "    with open(log_file_path, 'a') as log_file:\n",
    "        log_file.write(\"Skipped directories:\\n\")\n",
    "        for dir in skipped_directories:\n",
    "            log_file.write(f\"{dir}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get memory usage in bytes\n",
    "memory_usage = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "print(\"Memory usage end:\", memory_usage/1000000, \"GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# will do latest LH_ set in loop as a test\n",
    "label_z = 'z = 0.46'\n",
    "\n",
    "\n",
    "# Plot the luminosity function\n",
    "plt.errorbar(massBinLimits, phi, yerr=phi_sigma, fmt='o', color='blue',label=label_z)\n",
    "plt.xlabel('Absolute Magnitude (AB)')\n",
    "plt.ylabel('Number Density (Mpc^-3 mag^-1)')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.title('Luminosity Function XMM-OM filter')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
